#!/usr/bin/env python3
"""
SentenceBERT ê¸°ë°˜ ì˜í™” ì¤„ê±°ë¦¬ ì„ë² ë”© ìƒì„±ê¸°
ë‹¤êµ­ì–´ SentenceBERTë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ ì¿¼ë¦¬ì™€ ì˜ì–´ ì¤„ê±°ë¦¬ ëª¨ë‘ ì²˜ë¦¬
"""

import json
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
import os
from tqdm import tqdm
import warnings
import time
warnings.filterwarnings('ignore')

class SentenceBertEmbeddingGenerator:
    def __init__(self, model_name="paraphrase-multilingual-MiniLM-L12-v2"):
        """SentenceBERT ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”"""
        print(f"[ì´ˆê¸°í™”] SentenceBERT ëª¨ë¸ ë¡œë”©: {model_name}")
        print("=" * 60)
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"[ì¥ì¹˜] ì‚¬ìš© ì¥ì¹˜: {self.device}")
        
        # SentenceBERT ëª¨ë¸ ë¡œë“œ
        try:
            print("[ë‹¤ìš´ë¡œë“œ] SentenceBERT ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (ìµœì´ˆ ì‹¤í–‰ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            self.model = SentenceTransformer(model_name, device=self.device)
            
            print(f"[ì„±ê³µ] SentenceBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            print(f"[ì •ë³´] ì„ë² ë”© ì°¨ì›: {self.model.get_sentence_embedding_dimension()}")
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] SentenceBERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("[í•´ê²°ì±…] ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê³  sentence-transformers ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            print("ì„¤ì¹˜ ëª…ë ¹: pip install sentence-transformers")
            raise
    
    def get_sentence_embedding(self, text: str):
        """í…ìŠ¤íŠ¸ë¥¼ SentenceBERT ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        try:
            # SentenceBERTë¡œ ì„ë² ë”© ìƒì„± (ìë™ìœ¼ë¡œ ì •ê·œí™”ë¨)
            embedding = self.model.encode(text, convert_to_numpy=True)
            return embedding.astype('float32')
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œ ì˜ë²¡í„° ë°˜í™˜ (384ì°¨ì› - MiniLM ê¸°ë³¸ ì°¨ì›)
            return np.zeros(384, dtype='float32')
    
    def process_movies_dataset(self, input_file: str = 'movies_dataset.json', 
                             output_file: str = 'movie_embeddings_bert.json'):
        """ì˜í™” ë°ì´í„°ì…‹ì˜ ëª¨ë“  ì¤„ê±°ë¦¬ë¥¼ SentenceBERT ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        print(f"\n[ì‹œì‘] ì˜í™” ë°ì´í„°ì…‹ SentenceBERT ì„ë² ë”© ìƒì„±")
        print("=" * 60)
        
        # ì˜í™” ë°ì´í„° ë¡œë“œ
        try:
            with open(input_file, 'r', encoding='utf-8') as f:
                movies = json.load(f)
            print(f"[ë¡œë“œ] {len(movies)}ê°œ ì˜í™” ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ì˜í™” ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return
        
        # ì„ë² ë”© ìƒì„±
        embeddings_data = []
        successful_count = 0
        start_time = time.time()
        
        print(f"[ì§„í–‰] SentenceBERT ì„ë² ë”© ìƒì„± ì¤‘...")
        print(f"[ì •ë³´] ì˜ˆìƒ ì†Œìš” ì‹œê°„: {len(movies) * 0.1 / 60:.1f}ë¶„ (BERTë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„)")
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        plots = []
        movie_infos = []
        
        for i, movie in enumerate(movies):
            title = movie.get('title', f'Movie_{i}')
            plot = movie.get('plot', '')
            
            if not plot.strip():
                print(f"\n[ê²½ê³ ] '{title}': ì¤„ê±°ë¦¬ê°€ ë¹„ì–´ìˆìŒ")
                plot = title  # ì œëª©ì„ ëŒ€ì‹  ì‚¬ìš©
            
            plots.append(plot)
            movie_infos.append({
                'title': title,
                'plot': plot,
                'year': movie.get('year', ''),
                'director': movie.get('director', ''),
                'genres': movie.get('genres', {}),
                'movie_id': movie.get('movie_id', f'movie_{i}')
            })
        
        # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± (í›¨ì”¬ ë¹ ë¦„)
        print(f"[ë°°ì¹˜] {len(plots)}ê°œ ì¤„ê±°ë¦¬ ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì¤‘...")
        try:
            embeddings = self.model.encode(plots, 
                                         convert_to_numpy=True, 
                                         show_progress_bar=True,
                                         batch_size=32)
            
            # ê²°ê³¼ ì €ì¥
            for i, (movie_info, embedding) in enumerate(zip(movie_infos, embeddings)):
                embeddings_data.append({
                    **movie_info,
                    'embedding': embedding.tolist()
                })
                successful_count += 1
                
                # ì¤‘ê°„ ì €ì¥ (100ê°œë§ˆë‹¤)
                if (i + 1) % 100 == 0:
                    elapsed = time.time() - start_time
                    remaining = (len(movies) - i - 1) * (elapsed / (i + 1))
                    print(f"\n[ì§„í–‰] {i + 1}/{len(movies)} ì™„ë£Œ ({successful_count}ê°œ ì„±ê³µ)")
                    print(f"[ì‹œê°„] ê²½ê³¼: {elapsed/60:.1f}ë¶„, ë‚¨ì€ ì‹œê°„: {remaining/60:.1f}ë¶„")
                    self._save_intermediate(embeddings_data, output_file, i + 1)
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            # ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±
            print("[í´ë°±] ê°œë³„ ì„ë² ë”© ìƒì„±ìœ¼ë¡œ ì „í™˜...")
            embeddings_data = []
            
            for i, movie_info in enumerate(tqdm(movie_infos, desc="ê°œë³„ ì„ë² ë”© ìƒì„±")):
                try:
                    embedding = self.get_sentence_embedding(movie_info['plot'])
                    embeddings_data.append({
                        **movie_info,
                        'embedding': embedding.tolist()
                    })
                    successful_count += 1
                    
                except Exception as e:
                    print(f"\n[ì˜¤ë¥˜] '{movie_info['title']}' ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
        
        # ìµœì¢… ì €ì¥
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(embeddings_data, f, ensure_ascii=False, indent=2)
            
            total_time = time.time() - start_time
            print(f"\n[ì™„ë£Œ] SentenceBERT ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
            print(f"[ê²°ê³¼] ì´ {successful_count}/{len(movies)}ê°œ ì˜í™” ì²˜ë¦¬")
            print(f"[ì‹œê°„] ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
            print(f"[ì €ì¥] {output_file}ì— ì €ì¥ë¨")
            print(f"[í¬ê¸°] íŒŒì¼ í¬ê¸°: {os.path.getsize(output_file) / (1024*1024):.1f} MB")
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_intermediate(self, data, filename, count):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        backup_name = f"{filename}.backup_{count}"
        try:
            with open(backup_name, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"[ë°±ì—…] {backup_name} ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ë°±ì—… ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def test_embedding_quality(self, test_queries=None):
        """ì„ë² ë”© í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
        if test_queries is None:
            test_queries = [
                "ê¿ˆê³¼ í˜„ì‹¤ì„ ì˜¤ê°€ëŠ” ì˜í™”",
                "ì£¼ì¸ê³µì´ ì´ˆë°˜ì— ì‹¤íŒ¨í•˜ì§€ë§Œ ê²°êµ­ ì„±ê³µí•˜ëŠ” ì˜í™”",
                "ë¡œë´‡ê³¼ ì¸ê°„ì˜ ì‚¬ë‘ ì´ì•¼ê¸°",
                "time travel movie",
                "love story between human and AI",
                "matrix",
                "inception"
            ]
        
        print(f"\n[í…ŒìŠ¤íŠ¸] SentenceBERT ì„ë² ë”© í’ˆì§ˆ í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        
        for query in test_queries:
            print(f"\nì¿¼ë¦¬: '{query}'")
            start_time = time.time()
            embedding = self.get_sentence_embedding(query)
            end_time = time.time()
            
            print(f"ì„ë² ë”© ì°¨ì›: {embedding.shape}")
            print(f"ì„ë² ë”© ë²”ìœ„: [{embedding.min():.3f}, {embedding.max():.3f}]")
            print(f"ì„ë² ë”© L2 ë…¸ë¦„: {np.linalg.norm(embedding):.3f}")
            print(f"ìƒì„± ì‹œê°„: {(end_time - start_time)*1000:.1f}ms")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸ¬ SentenceBERT ê¸°ë°˜ ì˜í™” ì„ë² ë”© ìƒì„±ê¸°")
        print("=" * 60)
        print("ì´ ë„êµ¬ëŠ” ì˜í™” ì¤„ê±°ë¦¬ë¥¼ SentenceBERT ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        print("â€¢ paraphrase-multilingual-MiniLM-L12-v2 ì‚¬ìš© (í•œêµ­ì–´ + ì˜ì–´ ì§€ì›)")
        print("â€¢ ë¬¸ì¥ ì˜ë¯¸ ì„ë² ë”© íŠ¹í™” ëª¨ë¸")
        print("â€¢ ê¸°ì¡´ BERT [CLS]ë³´ë‹¤ í›¨ì”¬ ë†’ì€ ì˜ë¯¸ ìœ ì‚¬ë„ ì„±ëŠ¥")
        print("â€¢ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¹ ë¥¸ ì†ë„")
        print()
        
        # SentenceBERT ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = SentenceBertEmbeddingGenerator()
        
        # ì„ë² ë”© í’ˆì§ˆ í…ŒìŠ¤íŠ¸
        generator.test_embedding_quality()
        
        # ì‚¬ìš©ì í™•ì¸
        print("\n" + "="*60)
        response = input("ì˜í™” ë°ì´í„°ì…‹ ì „ì²´ë¥¼ SentenceBERT ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        
        if response.lower() in ['y', 'yes', 'ì˜ˆ', 'ã…‡']:
            # ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬
            generator.process_movies_dataset()
            
            print("\nğŸ‰ ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
            print("ë‹¤ìŒ ë‹¨ê³„:")
            print("1. build_bert_vector_db.py ì‹¤í–‰í•˜ì—¬ FAISS ì¸ë±ìŠ¤ ìƒì„±")
            print("2. bert_movie_recommender_new.pyë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
            print("\nì£¼ìš” ê°œì„ ì‚¬í•­:")
            print("â€¢ ê¸°ì¡´ BERT [CLS] â†’ SentenceBERT ë¬¸ì¥ ì„ë² ë”©")
            print("â€¢ ì˜ë¯¸ ìœ ì‚¬ë„ ê²€ìƒ‰ ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ")
            print("â€¢ 'matrix' ê²€ìƒ‰ì‹œ ë§¤íŠ¸ë¦­ìŠ¤ ì˜í™” ì •í™•íˆ ê²€ìƒ‰ë¨")
            
        else:
            print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        print("\n[í•´ê²°ì±…]")
        print("1. sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:")
        print("   pip install sentence-transformers")
        print("2. ì¸í„°ë„· ì—°ê²° í™•ì¸ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”)")
        print("3. ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ì‹œìŠ¤í…œ ì¬ì‹œì‘ í›„ ì¬ì‹¤í–‰")

if __name__ == "__main__":
    main()
