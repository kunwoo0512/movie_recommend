#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Multimodal Movie Similarity Calculator (ê¸°ì¡´ ë°©ì‹ ê¸°ë°˜)

ì¤„ê±°ë¦¬(ì²­í‚¹ í›„ í‰ê· ) + íë¦„ê³¡ì„ (384ì°¨ì› í™•ì¥) + ì¥ë¥´(384ì°¨ì› í™•ì¥)ì„ 
ì‚¬ìš©ì ì§€ì • ê°€ì¤‘ì¹˜ë¡œ ì‹¤ì‹œê°„ ê²°í•©í•˜ì—¬ ìœ ì‚¬ ì˜í™” ê²€ìƒ‰
"""

import os
import json
import numpy as np
import faiss
import re
import torch
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
from pathlib import Path

class MultimodalSimilarityCalculator:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.movie_metadata = None
        self.sbert_model = None
        self.embedding_dim = 384
        self.initialized = False
        
        # ë¯¸ë¦¬ ê³„ì‚°ëœ ì„ë² ë”© ìºì‹œ
        self.plot_embeddings_cache = None
        self.flow_embeddings_cache = None
        self.genre_embeddings_cache = None
        
    def load_all_data(self):
        """ëª¨ë“  ë°ì´í„°ì™€ ëª¨ë¸ ë¡œë“œ"""
        try:
            print("ğŸš€ ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # SentenceBERT ëª¨ë¸ ë¡œë“œ
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            print(f"ğŸ“± ë””ë°”ì´ìŠ¤: {device}")
            
            self.sbert_model = SentenceTransformer(
                'paraphrase-multilingual-MiniLM-L12-v2', 
                device=device
            )
            print("ğŸ¤– SentenceBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # ì˜í™” ë©”íƒ€ë°ì´í„° ë¡œë“œ (plot í¬í•¨)
            metadata_path = os.path.join(self.data_dir, "multimodal_metadata.jsonl")
            if not os.path.exists(metadata_path):
                print(f"âŒ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_path}")
                return False
                
            self.movie_metadata = []
            with open(metadata_path, 'r', encoding='utf-8') as f:
                for line in f:
                    self.movie_metadata.append(json.loads(line.strip()))
            
            print(f"ğŸ“Š {len(self.movie_metadata)}ê°œ ì˜í™” ë©”íƒ€ë°ì´í„° ë¡œë“œ")
            
            # ê° ëª¨ë‹¬ë¦¬í‹°ë³„ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°
            self._precompute_embeddings()
            
            self.initialized = True
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def split_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• """
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        return sentences
    
    def create_plot_chunks(self, plot: str, window_size: int = 2, stride: int = 1) -> List[str]:
        """ì¤„ê±°ë¦¬ë¥¼ ì²­í‚¹"""
        sentences = self.split_sentences(plot)
        
        if len(sentences) <= window_size:
            return [plot]
        
        chunks = []
        for i in range(0, len(sentences) - window_size + 1, stride):
            chunk = ' '.join(sentences[i:i + window_size])
            chunks.append(chunk)
        
        return chunks
    
    def get_plot_embedding(self, plot: str) -> np.ndarray:
        """ì¤„ê±°ë¦¬ ì„ë² ë”© ìƒì„± (ì²­í‚¹ í›„ í‰ê· ) - ê¸°ì¡´ ë°©ì‹"""
        chunks = self.create_plot_chunks(plot)
        
        # ê° ì²­í¬ë¥¼ ì„ë² ë”©
        with torch.inference_mode():
            chunk_embeddings = self.sbert_model.encode(
                chunks, 
                convert_to_numpy=True, 
                normalize_embeddings=True
            )
        
        # ì²­í¬ë“¤ì˜ í‰ê· ìœ¼ë¡œ ì˜í™” ëŒ€í‘œ ì„ë² ë”© ìƒì„±
        if len(chunk_embeddings.shape) == 1:
            chunk_embeddings = chunk_embeddings.reshape(1, -1)
            
        movie_plot_embedding = np.mean(chunk_embeddings, axis=0)
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(movie_plot_embedding)
        if norm > 0:
            movie_plot_embedding = movie_plot_embedding / norm
            
        return movie_plot_embedding.astype('float32')
    
    def get_flow_embedding(self, flow_curve: List[float]) -> np.ndarray:
        """íë¦„ê³¡ì„  ì„ë² ë”© ìƒì„± (384ì°¨ì› í™•ì¥) - ê¸°ì¡´ ë°©ì‹"""
        # íë¦„ê³¡ì„ ì„ 0-1ë¡œ ì •ê·œí™”
        flow_array = np.array(flow_curve, dtype='float32')
        flow_normalized = flow_array / 10.0  # 0-10 ìŠ¤ì¼€ì¼ì„ 0-1ë¡œ
        
        # 10ê°œ ê°’ì„ 384ì°¨ì›ìœ¼ë¡œ í™•ì¥
        # 10ê°œ ê°’ì„ 38ë²ˆ ë°˜ë³µ (380ì°¨ì›) + í‰ê· ê°’ 4ê°œ
        expanded_flow = np.tile(flow_normalized, 38)  # 380ì°¨ì›
        
        # ë‚˜ë¨¸ì§€ 4ì°¨ì›ì€ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€
        avg_flow = np.mean(flow_normalized)
        flow_padding = np.full(4, avg_flow, dtype='float32')
        
        flow_embedding = np.concatenate([expanded_flow, flow_padding])
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(flow_embedding)
        if norm > 0:
            flow_embedding = flow_embedding / norm
            
        return flow_embedding
    
    def get_genre_embedding(self, genres: Dict[str, int]) -> np.ndarray:
        """ì¥ë¥´ ì ìˆ˜ ì„ë² ë”© ìƒì„± (384ì°¨ì› í™•ì¥) - ê¸°ì¡´ ë°©ì‹"""
        # ì¥ë¥´ ìˆœì„œ ê³ ì •
        genre_names = ['action', 'thriller', 'romance', 'drama', 'comedy', 'sci_fi', 'horror']
        
        # ì¥ë¥´ ì ìˆ˜ ë²¡í„° ìƒì„±
        genre_scores = []
        for genre in genre_names:
            score = genres.get(genre, 0) / 10.0  # 0-10ì„ 0-1ë¡œ ì •ê·œí™”
            genre_scores.append(score)
        
        genre_array = np.array(genre_scores, dtype='float32')
        
        # 7ê°œ ì¥ë¥´ë¥¼ 384ì°¨ì›ìœ¼ë¡œ í™•ì¥
        # 7ê°œ ê°’ì„ 54ë²ˆ ë°˜ë³µ (378ì°¨ì›) + í‰ê· ê°’ 6ê°œ
        expanded_genre = np.tile(genre_array, 54)  # 378ì°¨ì› (7 * 54)
        
        # ë‚˜ë¨¸ì§€ 6ì°¨ì›ì€ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€
        avg_genre = np.mean(genre_array)
        genre_padding = np.full(6, avg_genre, dtype='float32')
        
        genre_embedding = np.concatenate([expanded_genre, genre_padding])
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(genre_embedding)
        if norm > 0:
            genre_embedding = genre_embedding / norm
            
        return genre_embedding
    
    def _precompute_embeddings(self):
        """ëª¨ë“  ì˜í™”ì˜ ê° ëª¨ë‹¬ë¦¬í‹°ë³„ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°"""
        print("ğŸ“Š ëª¨ë“  ì˜í™”ì˜ ì„ë² ë”© ì‚¬ì „ ê³„ì‚° ì¤‘...")
        
        plot_embeddings = []
        flow_embeddings = []
        genre_embeddings = []
        
        for i, movie in enumerate(self.movie_metadata):
            if i % 100 == 0:
                print(f"   ì§„í–‰ë¥ : {i}/{len(self.movie_metadata)}")
            
            # ê° ëª¨ë‹¬ë¦¬í‹°ë³„ ì„ë² ë”© ê³„ì‚°
            plot_emb = self.get_plot_embedding(movie['plot'])
            flow_emb = self.get_flow_embedding(movie['flow_curve'])
            genre_emb = self.get_genre_embedding(movie['genres'])
            
            plot_embeddings.append(plot_emb)
            flow_embeddings.append(flow_emb)
            genre_embeddings.append(genre_emb)
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        self.plot_embeddings_cache = np.array(plot_embeddings, dtype='float32')
        self.flow_embeddings_cache = np.array(flow_embeddings, dtype='float32')
        self.genre_embeddings_cache = np.array(genre_embeddings, dtype='float32')
        
        print("âœ… ì„ë² ë”© ì‚¬ì „ ê³„ì‚° ì™„ë£Œ")
    
    def find_movie_by_title(self, title: str):
        """ì˜í™” ì œëª©ìœ¼ë¡œ ì°¾ê¸°"""
        title_lower = title.lower().strip()
        
        for i, movie in enumerate(self.movie_metadata):
            movie_title = movie.get('title', '').lower().strip()
            if title_lower == movie_title:
                return movie, i
                
            # ì—°ë„ í¬í•¨ëœ ê²½ìš° ì²˜ë¦¬
            if '(' in movie_title and ')' in movie_title:
                title_without_year = movie_title.split('(')[0].strip()
                if title_lower == title_without_year:
                    return movie, i
        
        return None, -1
    
    def create_combined_embedding(self, movie_idx: int, w_plot: float, w_flow: float, w_genre: float) -> np.ndarray:
        """ì‚¬ìš©ì ì§€ì • ê°€ì¤‘ì¹˜ë¡œ ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ìƒì„±"""
        # ê° ëª¨ë‹¬ë¦¬í‹° ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°
        plot_emb = self.plot_embeddings_cache[movie_idx]
        flow_emb = self.flow_embeddings_cache[movie_idx]
        genre_emb = self.genre_embeddings_cache[movie_idx]
        
        # ê°€ì¤‘ ê²°í•© (ê¸°ì¡´ ë°©ì‹ê³¼ ë™ì¼)
        total_weight = w_plot + w_flow + w_genre
        combined_embedding = (
            plot_emb * (w_plot / total_weight) +
            flow_emb * (w_flow / total_weight) + 
            genre_emb * (w_genre / total_weight)
        )
        
        # ìµœì¢… ì •ê·œí™”
        norm = np.linalg.norm(combined_embedding)
        if norm > 0:
            combined_embedding = combined_embedding / norm
            
        return combined_embedding
    
    def calculate_weighted_similarity(self, movie_title: str, w_plot: float = 0.65, 
                                    w_flow: float = 0.25, w_genre: float = 0.10, 
                                    top_k: int = 10):
        """ê°€ì¤‘ì¹˜ ì¡°ì ˆ ê°€ëŠ¥í•œ ìœ ì‚¬ ì˜í™” ê²€ìƒ‰ (ê¸°ì¡´ ë°©ì‹ ê¸°ë°˜)"""
        if not self.initialized:
            if not self.load_all_data():
                raise RuntimeError("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        
        print(f"ğŸ” '{movie_title}' ìœ ì‚¬ ì˜í™” ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: plot={w_plot:.2f}, flow={w_flow:.2f}, genre={w_genre:.2f})")
        
        # ëŒ€ìƒ ì˜í™” ì°¾ê¸°
        target_movie, target_idx = self.find_movie_by_title(movie_title)
        if target_movie is None:
            raise ValueError(f"ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{movie_title}'")
        
        print(f"ğŸ¯ ëŒ€ìƒ ì˜í™”: {target_movie['title']} ({target_movie['year']})")
        
        # ëª¨ë“  ì˜í™”ì˜ ê°€ì¤‘ ê²°í•© ì„ë² ë”© ìƒì„±
        print("âš–ï¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„ë² ë”© ìƒì„± ì¤‘...")
        all_embeddings = []
        for i in range(len(self.movie_metadata)):
            combined_emb = self.create_combined_embedding(i, w_plot, w_flow, w_genre)
            all_embeddings.append(combined_emb)
        
        embeddings_array = np.array(all_embeddings, dtype='float32')
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„± (ì‹¤ì‹œê°„)
        index = faiss.IndexFlatIP(self.embedding_dim)  # ë‚´ì  ê¸°ë°˜ (ì •ê·œí™”ëœ ë²¡í„°ì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        index.add(embeddings_array)
        
        # ëŒ€ìƒ ì˜í™” ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰
        query_embedding = embeddings_array[target_idx:target_idx+1]
        similarities, indices = index.search(query_embedding, top_k + 1)  # ìê¸° ìì‹  í¬í•¨
        
        # ê²°ê³¼ ì •ë¦¬
        similar_movies = []
        for i, (sim, idx) in enumerate(zip(similarities[0], indices[0])):
            # ìê¸° ìì‹  ì œì™¸
            if idx == target_idx:
                continue
            
            if len(similar_movies) >= top_k:
                break
                
            movie_meta = self.movie_metadata[idx]
            similar_movies.append({
                'rank': len(similar_movies) + 1,
                'title': movie_meta['title'],
                'year': movie_meta['year'],
                'director': movie_meta['director'],
                'similarity_score': float(sim),
                'genres': movie_meta['genres'],
                'flow_curve': movie_meta['flow_curve'],
                'plot': movie_meta['plot'][:200] + "..." if len(movie_meta['plot']) > 200 else movie_meta['plot'],
                'poster': movie_meta.get('poster', ''),
                'weights_used': {
                    'plot': w_plot / (w_plot + w_flow + w_genre),
                    'flow': w_flow / (w_plot + w_flow + w_genre),
                    'genre': w_genre / (w_plot + w_flow + w_genre)
                }
            })
        
        return similar_movies

# Factory function
def get_weighted_calculator(data_dir: str = "data"):
    """MultimodalSimilarityCalculator ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return MultimodalSimilarityCalculator(data_dir)

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    calculator = get_weighted_calculator()
    if calculator.load_all_data():
        print("\nğŸ§ª Inception í…ŒìŠ¤íŠ¸...")
        results = calculator.calculate_weighted_similarity("Inception", top_k=5)
        
        for movie in results:
            print(f"\n{movie['rank']}. {movie['title']} ({movie['year']})")
            print(f"   ê°ë…: {movie['director']}")
            print(f"   ìœ ì‚¬ë„: {movie['similarity_score']:.4f}")
            weights = movie['weights_used']
            print(f"   ê°€ì¤‘ì¹˜: plot={weights['plot']:.2f}, flow={weights['flow']:.2f}, genre={weights['genre']:.2f}")
    else:
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")