#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Multimodal Movie Similarity Calculator

ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°(ì¤„ê±°ë¦¬/íë¦„/ì¥ë¥´)ë¥¼ í†µì¼ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ìƒˆë¡œ ìƒì„±í•˜ì—¬
ì‚¬ìš©ì ì§€ì • ê°€ì¤‘ì¹˜ë¡œ ê°œë³„ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ìµœì¢… ì¶”ì²œ ì œê³µ
"""

import os
import json
import numpy as np
import faiss
import re
import torch
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
from pathlib import Path

class UnifiedMultimodalCalculator:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.movie_metadata = None  # flow_curve, genres í¬í•¨
        self.plot_metadata = None   # plot í¬í•¨ 
        self.sbert_model = None
        self.embedding_dim = 384
        
        # ê°œë³„ FAISS ì¸ë±ìŠ¤ë“¤
        self.plot_index = None
        self.flow_index = None
        self.genre_index = None
        
        self.initialized = False
        
    def load_all_data(self):
        """ëª¨ë“  ë°ì´í„°ì™€ ëª¨ë¸ ë¡œë“œ"""
        try:
            print("[System] í†µí•© ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # PyTorch meta tensor ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ê°•ì œ ì„¤ì •
            import torch
            import os
            
            # CUDA ì™„ì „ ë¹„í™œì„±í™”
            torch.cuda.is_available = lambda: False
            os.environ['CUDA_VISIBLE_DEVICES'] = ''
            
            # SentenceBERT ëª¨ë¸ ë¡œë“œ
            device = 'cpu'  # ê°•ì œë¡œ CPU ì‚¬ìš©
            print(f"[Device] ë””ë°”ì´ìŠ¤: {device} (ê°•ì œ CPU ëª¨ë“œ)")
            
            try:
                # meta tensor ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ CPUì—ì„œë§Œ ë¡œë“œ
                print("[Model] SentenceBERT ëª¨ë¸ì„ CPUì—ì„œ ë¡œë“œ ì¤‘...")
                
                # í™˜ê²½ë³€ìˆ˜ë¡œ CPU ê°•ì œ ì„¤ì •
                import sentence_transformers
                
                self.sbert_model = SentenceTransformer(
                    'paraphrase-multilingual-MiniLM-L12-v2', 
                    device='cpu'  # í•­ìƒ CPUì—ì„œ ë¡œë“œ
                )
                
                # ëª¨ë¸ì„ ëª…ì‹œì ìœ¼ë¡œ CPUë¡œ ì´ë™
                self.sbert_model.to('cpu')
                
                print("[Model] SentenceBERT ëª¨ë¸ CPUì—ì„œ ë¡œë“œ ì™„ë£Œ")
                    
            except Exception as e:
                print(f"[Error] SentenceBERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                # í´ë°±: ë” ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš©
                print("[Fallback] ê¸°ë³¸ ëª¨ë¸ë¡œ ì¬ì‹œë„...")
                try:
                    self.sbert_model = SentenceTransformer(
                        'all-MiniLM-L6-v2',
                        device='cpu'
                    )
                    self.sbert_model.to('cpu')
                    print("[Model] ê¸°ë³¸ SentenceBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                except Exception as e2:
                    print(f"[Error] ê¸°ë³¸ ëª¨ë¸ë„ ì‹¤íŒ¨: {str(e2)}")
                    # ê°€ì¥ ë‹¨ìˆœí•œ ëª¨ë¸ ì‹œë„
                    self.sbert_model = SentenceTransformer(
                        'sentence-transformers/all-MiniLM-L6-v2',
                        device='cpu'
                    )
                    self.sbert_model.to('cpu')
                    print("[Model] ìµœì†Œ SentenceBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # ì˜í™” ë©”íƒ€ë°ì´í„° ë¡œë“œ (íë¦„/ì¥ë¥´ìš©)
            metadata_path = os.path.join(self.data_dir, "separated_embeddings", "movie_metadata.jsonl")
            if not os.path.exists(metadata_path):
                print(f"âŒ ì˜í™” ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_path}")
                return False
                
            self.movie_metadata = []
            with open(metadata_path, 'r', encoding='utf-8') as f:
                for line in f:
                    self.movie_metadata.append(json.loads(line.strip()))
            
            # ì¤„ê±°ë¦¬ ë©”íƒ€ë°ì´í„° ë¡œë“œ
            plot_metadata_path = os.path.join(self.data_dir, "multimodal_metadata.jsonl")
            if not os.path.exists(plot_metadata_path):
                print(f"âŒ ì¤„ê±°ë¦¬ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {plot_metadata_path}")
                return False
                
            self.plot_metadata = []
            with open(plot_metadata_path, 'r', encoding='utf-8') as f:
                for line in f:
                    self.plot_metadata.append(json.loads(line.strip()))
            
            print(f"[Data] {len(self.movie_metadata)}ê°œ ì˜í™” (íë¦„/ì¥ë¥´), {len(self.plot_metadata)}ê°œ ì˜í™” (ì¤„ê±°ë¦¬)")
            
            # ë°ì´í„° ì •í•©ì„± í™•ì¸
            if len(self.movie_metadata) != len(self.plot_metadata):
                print(f"âš ï¸ ë°ì´í„° ìˆ˜ ë¶ˆì¼ì¹˜: {len(self.movie_metadata)} vs {len(self.plot_metadata)}")
            
            # ì¸ë±ìŠ¤ë“¤ ìƒì„± ë˜ëŠ” ë¡œë“œ
            self._load_or_create_indices()
            
            self.initialized = True
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _load_or_create_indices(self):
        """ì¸ë±ìŠ¤ë“¤ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±"""
        base_path = os.path.join(self.data_dir, "unified_indices")
        os.makedirs(base_path, exist_ok=True)
        
        plot_index_path = os.path.join(base_path, "plot_index.faiss")
        flow_index_path = os.path.join(base_path, "flow_index.faiss") 
        genre_index_path = os.path.join(base_path, "genre_index.faiss")
        
        # ëª¨ë“  ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        all_exist = all([
            os.path.exists(plot_index_path),
            os.path.exists(flow_index_path),
            os.path.exists(genre_index_path)
        ])
        
        if all_exist:
            print("[Loading] ê¸°ì¡´ í†µí•© ì¸ë±ìŠ¤ë“¤ ë¡œë”© ì¤‘...")
            self.plot_index = faiss.read_index(plot_index_path)
            self.flow_index = faiss.read_index(flow_index_path)
            self.genre_index = faiss.read_index(genre_index_path)
            print("[Success] ëª¨ë“  ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        else:
            print("[Create] í†µí•© ì¸ë±ìŠ¤ë“¤ ìƒˆë¡œ ìƒì„± ì¤‘...")
            self._create_all_indices(base_path)
    
    def split_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• """
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        return sentences
    
    def create_plot_chunks(self, plot: str, window_size: int = 2, stride: int = 1) -> List[str]:
        """ì¤„ê±°ë¦¬ë¥¼ ì²­í‚¹ (ê¸°ì¡´ ë°©ì‹ê³¼ ë™ì¼)"""
        sentences = self.split_sentences(plot)
        
        if len(sentences) <= window_size:
            return [plot]
        
        chunks = []
        for i in range(0, len(sentences) - window_size + 1, stride):
            chunk = ' '.join(sentences[i:i + window_size])
            chunks.append(chunk)
        
        return chunks
    
    def get_plot_embedding(self, plot: str) -> np.ndarray:
        """ì¤„ê±°ë¦¬ ì„ë² ë”© ìƒì„± (ì²­í‚¹ í›„ í‰ê· )"""
        chunks = self.create_plot_chunks(plot)
        
        # ê° ì²­í¬ë¥¼ ì„ë² ë”©
        with torch.inference_mode():
            chunk_embeddings = self.sbert_model.encode(
                chunks, 
                convert_to_numpy=True, 
                normalize_embeddings=True,
                batch_size=32  # ë°°ì¹˜ í¬ê¸° ì œí•œ
            )
        
        # ì²­í¬ë“¤ì˜ í‰ê· ìœ¼ë¡œ ì˜í™” ëŒ€í‘œ ì„ë² ë”© ìƒì„±
        if len(chunk_embeddings.shape) == 1:
            chunk_embeddings = chunk_embeddings.reshape(1, -1)
            
        movie_plot_embedding = np.mean(chunk_embeddings, axis=0)
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(movie_plot_embedding)
        if norm > 0:
            movie_plot_embedding = movie_plot_embedding / norm
            
        return movie_plot_embedding.astype('float32')
    
    def get_flow_embedding(self, flow_curve: List[float]) -> np.ndarray:
        """íë¦„ê³¡ì„  ì„ë² ë”© ìƒì„± (384ì°¨ì› í™•ì¥)"""
        flow_array = np.array(flow_curve, dtype='float32')
        flow_normalized = flow_array / 10.0  # 0-10 ìŠ¤ì¼€ì¼ì„ 0-1ë¡œ
        
        # 10ê°œ ê°’ì„ 384ì°¨ì›ìœ¼ë¡œ í™•ì¥
        expanded_flow = np.tile(flow_normalized, 38)  # 380ì°¨ì›
        
        # ë‚˜ë¨¸ì§€ 4ì°¨ì›ì€ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€
        avg_flow = np.mean(flow_normalized)
        flow_padding = np.full(4, avg_flow, dtype='float32')
        
        flow_embedding = np.concatenate([expanded_flow, flow_padding])
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(flow_embedding)
        if norm > 0:
            flow_embedding = flow_embedding / norm
            
        return flow_embedding
    
    def get_genre_embedding(self, genres: Dict[str, int]) -> np.ndarray:
        """ì¥ë¥´ ì ìˆ˜ ì„ë² ë”© ìƒì„± (384ì°¨ì› í™•ì¥)"""
        genre_names = ['action', 'thriller', 'romance', 'drama', 'comedy', 'sci_fi', 'horror']
        
        # ì¥ë¥´ ì ìˆ˜ ë²¡í„° ìƒì„±
        genre_scores = []
        for genre in genre_names:
            score = genres.get(genre, 0) / 10.0  # 0-10ì„ 0-1ë¡œ ì •ê·œí™”
            genre_scores.append(score)
        
        genre_array = np.array(genre_scores, dtype='float32')
        
        # 7ê°œ ì¥ë¥´ë¥¼ 384ì°¨ì›ìœ¼ë¡œ í™•ì¥
        expanded_genre = np.tile(genre_array, 54)  # 378ì°¨ì› (7 * 54)
        
        # ë‚˜ë¨¸ì§€ 6ì°¨ì›ì€ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€
        avg_genre = np.mean(genre_array)
        genre_padding = np.full(6, avg_genre, dtype='float32')
        
        genre_embedding = np.concatenate([expanded_genre, genre_padding])
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(genre_embedding)
        if norm > 0:
            genre_embedding = genre_embedding / norm
            
        return genre_embedding
    
    def _create_all_indices(self, base_path: str):
        """ëª¨ë“  ì¸ë±ìŠ¤ ìƒˆë¡œ ìƒì„±"""
        print("[Create] ëª¨ë“  ì„ë² ë”© ê³„ì‚° ë° ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        
        plot_embeddings = []
        flow_embeddings = []
        genre_embeddings = []
        
        # ê° ì˜í™”ë³„ë¡œ ì„ë² ë”© ê³„ì‚°
        total_movies = len(self.movie_metadata)
        for i in range(total_movies):
            if i % 50 == 0:
                print(f"   ì§„í–‰ë¥ : {i}/{total_movies}")
            
            # ì¤„ê±°ë¦¬ ì„ë² ë”© (multimodal_metadataì—ì„œ)
            plot_meta = self.plot_metadata[i]
            plot_emb = self.get_plot_embedding(plot_meta['plot'])
            plot_embeddings.append(plot_emb)
            
            # íë¦„/ì¥ë¥´ ì„ë² ë”© (movie_metadataì—ì„œ)
            movie_meta = self.movie_metadata[i]
            flow_emb = self.get_flow_embedding(movie_meta['flow_curve'])
            genre_emb = self.get_genre_embedding(movie_meta['genres'])
            
            flow_embeddings.append(flow_emb)
            genre_embeddings.append(genre_emb)
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        plot_array = np.array(plot_embeddings, dtype='float32')
        flow_array = np.array(flow_embeddings, dtype='float32')
        genre_array = np.array(genre_embeddings, dtype='float32')
        
        print(f"[Complete] ì„ë² ë”© ê³„ì‚° ì™„ë£Œ: Plot({plot_array.shape}), Flow({flow_array.shape}), Genre({genre_array.shape})")
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„± (ë‚´ì  ê¸°ë°˜)
        self.plot_index = faiss.IndexFlatIP(self.embedding_dim)
        self.flow_index = faiss.IndexFlatIP(self.embedding_dim)
        self.genre_index = faiss.IndexFlatIP(self.embedding_dim)
        
        # ì„ë² ë”© ì¶”ê°€
        self.plot_index.add(plot_array)
        self.flow_index.add(flow_array)
        self.genre_index.add(genre_array)
        
        # ì¸ë±ìŠ¤ ì €ì¥
        faiss.write_index(self.plot_index, os.path.join(base_path, "plot_index.faiss"))
        faiss.write_index(self.flow_index, os.path.join(base_path, "flow_index.faiss"))
        faiss.write_index(self.genre_index, os.path.join(base_path, "genre_index.faiss"))
        
        print("[Save] ëª¨ë“  ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ")
    
    def find_movie_by_title(self, title: str):
        """ì˜í™” ì œëª©ìœ¼ë¡œ ì°¾ê¸°"""
        title_lower = title.lower().strip()
        
        # ì…ë ¥ ì œëª©ì—ì„œ ì—°ë„ ë¶„ë¦¬
        input_title = title_lower
        input_year = None
        if '(' in title_lower and ')' in title_lower:
            parts = title_lower.split('(')
            input_title = parts[0].strip()
            year_part = parts[1].split(')')[0].strip()
            if year_part.isdigit():
                input_year = year_part
        
        for i, movie in enumerate(self.movie_metadata):
            movie_title = movie.get('title', '').lower().strip()
            movie_year = str(movie.get('year', '')).strip()
            
            # ì •í™•í•œ ë§¤ì¹­ (ì œëª©ë§Œ)
            if input_title == movie_title:
                # ì—°ë„ê¹Œì§€ ì§€ì •ëœ ê²½ìš° ì—°ë„ë„ í™•ì¸
                if input_year and input_year != movie_year:
                    continue
                return movie, i
            
            # ì˜í™” ì œëª©ì—ì„œ ì—°ë„ ì œê±°í•˜ê³  ë¹„êµ
            if '(' in movie_title and ')' in movie_title:
                title_without_year = movie_title.split('(')[0].strip()
                if input_title == title_without_year:
                    # ì—°ë„ê¹Œì§€ ì§€ì •ëœ ê²½ìš° ì—°ë„ë„ í™•ì¸
                    if input_year and input_year != movie_year:
                        continue
                    return movie, i
        
        return None, -1
    
    def search_plot_similarity(self, movie_idx: int, k: int = 10):
        """ì¤„ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰"""
        similarities, indices = self.plot_index.search(
            np.array([self.plot_index.reconstruct(movie_idx)]), k + 1
        )
        
        results = []
        for sim, idx in zip(similarities[0], indices[0]):
            if idx != movie_idx and len(results) < k:  # ìê¸° ìì‹  ì œì™¸
                movie = self.movie_metadata[idx]
                results.append({
                    'index': idx,
                    'title': movie['title'],
                    'year': movie['year'],
                    'similarity': float(sim)
                })
        
        return results
    
    def search_flow_similarity(self, movie_idx: int, k: int = 10):
        """íë¦„ê³¡ì„  ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰"""
        similarities, indices = self.flow_index.search(
            np.array([self.flow_index.reconstruct(movie_idx)]), k + 1
        )
        
        results = []
        for sim, idx in zip(similarities[0], indices[0]):
            if idx != movie_idx and len(results) < k:  # ìê¸° ìì‹  ì œì™¸
                movie = self.movie_metadata[idx]
                results.append({
                    'index': idx,
                    'title': movie['title'],
                    'year': movie['year'],
                    'similarity': float(sim)
                })
        
        return results
    
    def search_genre_similarity(self, movie_idx: int, k: int = 10):
        """ì¥ë¥´ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰"""
        similarities, indices = self.genre_index.search(
            np.array([self.genre_index.reconstruct(movie_idx)]), k + 1
        )
        
        results = []
        for sim, idx in zip(similarities[0], indices[0]):
            if idx != movie_idx and len(results) < k:  # ìê¸° ìì‹  ì œì™¸
                movie = self.movie_metadata[idx]
                results.append({
                    'index': idx,
                    'title': movie['title'],
                    'year': movie['year'],
                    'similarity': float(sim)
                })
        
        return results
    
    def calculate_weighted_similarity(self, movie_title: str, w_plot: float = 0.8, 
                                    w_flow: float = 0.1, w_genre: float = 0.1, 
                                    top_k: int = 10):
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìœ ì‚¬ ì˜í™” ê²€ìƒ‰ - ëª¨ë“  í›„ë³´ì— ëŒ€í•´ ì§ì ‘ ê³„ì‚°"""
        if not self.initialized:
            if not self.load_all_data():
                raise RuntimeError("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        
        print(f"[Search] '{movie_title}' ìœ ì‚¬ ì˜í™” ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: plot={w_plot:.2f}, flow={w_flow:.2f}, genre={w_genre:.2f})")
        
        # ëŒ€ìƒ ì˜í™” ì°¾ê¸°
        target_movie, target_idx = self.find_movie_by_title(movie_title)
        if target_movie is None:
            raise ValueError(f"ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{movie_title}'")
        
        print(f"ğŸ¯ ëŒ€ìƒ ì˜í™”: {target_movie['title']} ({target_movie['year']}) - ì¸ë±ìŠ¤: {target_idx}")
        
        # ëŒ€ìƒ ì˜í™”ì˜ ì„ë² ë”© ë²¡í„°ë“¤ ê°€ì ¸ì˜¤ê¸°
        target_plot_vec = self.plot_index.reconstruct(target_idx)
        target_flow_vec = self.flow_index.reconstruct(target_idx)
        target_genre_vec = self.genre_index.reconstruct(target_idx)
        
        print(f"[Embeddings] ëŒ€ìƒ ì˜í™” ì„ë² ë”© ë²¡í„° ì¤€ë¹„ ì™„ë£Œ")
        print(f"[Debug] ë²¡í„° í¬ê¸°: plot={target_plot_vec.shape}, flow={target_flow_vec.shape}, genre={target_genre_vec.shape}")
        
        # ëª¨ë“  ì˜í™”ì— ëŒ€í•´ ì§ì ‘ ìœ ì‚¬ë„ ê³„ì‚°
        all_movies_scores = []
        total_movies = len(self.movie_metadata)
        
        print(f"[Calculating] ì „ì²´ {total_movies}ê°œ ì˜í™”ì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")
        
        for i in range(total_movies):
            if i == target_idx:  # ìê¸° ìì‹  ì œì™¸
                continue
                
            # ê° ëª¨ë‹¬ë¦¬í‹° ìœ ì‚¬ë„ ì§ì ‘ ê³„ì‚°
            candidate_plot_vec = self.plot_index.reconstruct(i)
            candidate_flow_vec = self.flow_index.reconstruct(i)
            candidate_genre_vec = self.genre_index.reconstruct(i)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ë‚´ì  - ì •ê·œí™”ëœ ë²¡í„°ì´ë¯€ë¡œ)
            plot_similarity = float(np.dot(target_plot_vec, candidate_plot_vec))
            flow_similarity = float(np.dot(target_flow_vec, candidate_flow_vec))
            genre_similarity = float(np.dot(target_genre_vec, candidate_genre_vec))
            
            # ê°€ì¤‘ì¹˜ ì ìš©í•œ ìµœì¢… ì ìˆ˜
            total_weight = w_plot + w_flow + w_genre
            weighted_score = (
                w_plot * plot_similarity +
                w_flow * flow_similarity +
                w_genre * genre_similarity
            ) / total_weight
            
            # ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
            movie_meta = self.movie_metadata[i]
            plot_meta = self.plot_metadata[i]
            
            all_movies_scores.append({
                'index': i,
                'title': movie_meta['title'],
                'year': movie_meta['year'],
                'director': movie_meta['director'],
                'similarity_score': weighted_score,
                'component_scores': {
                    'plot': plot_similarity,
                    'flow': flow_similarity,
                    'genre': genre_similarity
                },
                'weights_used': {
                    'plot': w_plot / total_weight,
                    'flow': w_flow / total_weight,
                    'genre': w_genre / total_weight
                },
                'genres': movie_meta['genres'],
                'flow_curve': movie_meta['flow_curve'],
                'plot': plot_meta['plot'][:200] + "..." if len(plot_meta['plot']) > 200 else plot_meta['plot'],
                'poster': movie_meta.get('poster', '')
            })
        
        # ìµœì¢… ì ìˆ˜ë¡œ ì •ë ¬
        all_movies_scores.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        # ìƒìœ„ top_kê°œ ì„ íƒ ë° ìˆœìœ„ ë¶€ì—¬
        final_results = all_movies_scores[:top_k]
        for i, movie in enumerate(final_results):
            movie['rank'] = i + 1
        
        print(f"âœ… ê³„ì‚° ì™„ë£Œ: ì´ {len(all_movies_scores)}ê°œ í›„ë³´ ì¤‘ ìƒìœ„ {len(final_results)}ê°œ ì„ íƒ")
        print(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {final_results[-1]['similarity_score']:.4f} ~ {final_results[0]['similarity_score']:.4f}")
        
        # ìƒìœ„ 3ê°œ ê²°ê³¼ì˜ ìƒì„¸ ì •ë³´ ì¶œë ¥
        print(f"[Top 3 Results]")
        for i, movie in enumerate(final_results[:3]):
            comp = movie['component_scores']
            print(f"  {i+1}. {movie['title']} ({movie['year']}) - ìµœì¢…ì ìˆ˜: {movie['similarity_score']:.4f}")
            print(f"     ì„¸ë¶€ì ìˆ˜: plot={comp['plot']:.3f}, flow={comp['flow']:.3f}, genre={comp['genre']:.3f}")
        
        return final_results

# Factory function
def get_weighted_calculator(data_dir: str = "data"):
    """UnifiedMultimodalCalculator ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return UnifiedMultimodalCalculator(data_dir)

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    calculator = get_weighted_calculator()
    if calculator.load_all_data():
        print("\nğŸ§ª Inception í…ŒìŠ¤íŠ¸...")
        results = calculator.calculate_weighted_similarity("Inception", top_k=5)
        
        for movie in results:
            print(f"\n{movie['rank']}. {movie['title']} ({movie['year']})")
            print(f"   ê°ë…: {movie['director']}")
            print(f"   ìœ ì‚¬ë„: {movie['similarity_score']:.4f}")
            comp = movie['component_scores']
            print(f"   ì„¸ë¶€: plot={comp['plot']:.3f}, flow={comp['flow']:.3f}, genre={comp['genre']:.3f}")
    else:
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")