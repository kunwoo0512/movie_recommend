#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒŒì¸íŠœë‹ëœ ë¶„ë¦¬ ì„ë² ë”© ì‹œìŠ¤í…œ (ì‚¬ìš©ì ê°€ì¤‘ì¹˜ ì¡°ì ˆ)
3ê°œ íƒ€ì…ì˜ ì„ë² ë”©ì„ ë¶„ë¦¬ ì €ì¥í•˜ì—¬ ì‹¤ì‹œê°„ ê°€ì¤‘ì¹˜ ì¡°ì ˆ ê°€ëŠ¥:
- ì¤„ê±°ë¦¬ ì„ë² ë”© (íŒŒì¸íŠœë‹ëœ SBERT)
- íë¦„ê³¡ì„  ì„ë² ë”© 
- ì¥ë¥´ ì„ë² ë”©
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional
import re
from sentence_transformers import SentenceTransformer
import torch
import faiss
import time

class FlexibleMultimodalSystem:
    def __init__(self):
        """íŒŒì¸íŠœë‹ëœ ë¶„ë¦¬ ì„ë² ë”© ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸš€ íŒŒì¸íŠœë‹ëœ ë¶„ë¦¬ ì„ë² ë”© ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        
        # íŒŒì¸íŠœë‹ëœ SBERT ëª¨ë¸ ë¡œë“œ (ì¿¼ë¦¬ ì„ë² ë”©ìš©)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self._load_finetuned_model()
        self.embedding_dim = 384
        
        # ë¶„ë¦¬ëœ ì„ë² ë”©ë“¤ê³¼ ë©”íƒ€ë°ì´í„°
        self.plot_embeddings = None
        self.flow_embeddings = None  
        self.genre_embeddings = None
        self.movie_metadata = None
        self.genre_info = None
        
        # FAISS ì¸ë±ìŠ¤ë“¤
        self.plot_index = None
        self.flow_index = None
        self.genre_index = None
        
        # ê¸°ë³¸ ê°€ì¤‘ì¹˜
        self.default_weights = {
            'plot': 0.6,
            'flow': 0.3,
            'genre': 0.1
        }
        
    def _load_finetuned_model(self):
        """íŒŒì¸íŠœë‹ëœ SBERT ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ¤– íŒŒì¸íŠœë‹ëœ SBERT ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        possible_paths = [
            "models/movie-finetuned-sbert",
            "models/finetuned_sbert", 
            "paraphrase-multilingual-MiniLM-L12-v2"
        ]
        
        model_path = None
        for path in possible_paths:
            if Path(path).exists() and (not Path(path).is_dir() or any(Path(path).iterdir())):
                model_path = path
                break
        
        if not model_path:
            model_path = "paraphrase-multilingual-MiniLM-L12-v2"
            
        self.sbert_model = SentenceTransformer(model_path, device=self.device)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        
    def load_separated_embeddings(self, embeddings_dir: str = "data/separated_embeddings"):
        """ë¶„ë¦¬ëœ ì„ë² ë”©ë“¤ì„ ë¡œë“œ"""
        print(f"\nğŸ“‚ ë¶„ë¦¬ëœ ì„ë² ë”© ë¡œë“œ ì¤‘: {embeddings_dir}")
        
        embeddings_path = Path(embeddings_dir)
        if not embeddings_path.exists():
            raise FileNotFoundError(f"ì„ë² ë”© ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {embeddings_dir}")
        
        # 1. ì¤„ê±°ë¦¬ ì„ë² ë”© ë¡œë“œ
        plot_file = embeddings_path / "plot_embeddings.npy"
        if plot_file.exists():
            self.plot_embeddings = np.load(plot_file)
            print(f"ğŸ“ ì¤„ê±°ë¦¬ ì„ë² ë”© ë¡œë“œ: {self.plot_embeddings.shape}")
        else:
            raise FileNotFoundError(f"ì¤„ê±°ë¦¬ ì„ë² ë”© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {plot_file}")
            
        # 2. íë¦„ê³¡ì„  ì„ë² ë”© ë¡œë“œ
        flow_file = embeddings_path / "flow_embeddings.npy"
        if flow_file.exists():
            self.flow_embeddings = np.load(flow_file)
            print(f"ğŸ“ˆ íë¦„ê³¡ì„  ì„ë² ë”© ë¡œë“œ: {self.flow_embeddings.shape}")
        else:
            raise FileNotFoundError(f"íë¦„ê³¡ì„  ì„ë² ë”© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {flow_file}")
            
        # 3. ì¥ë¥´ ì„ë² ë”© ë¡œë“œ
        genre_file = embeddings_path / "genre_embeddings.npy"
        if genre_file.exists():
            self.genre_embeddings = np.load(genre_file)
            print(f"ğŸ­ ì¥ë¥´ ì„ë² ë”© ë¡œë“œ: {self.genre_embeddings.shape}")
        else:
            raise FileNotFoundError(f"ì¥ë¥´ ì„ë² ë”© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {genre_file}")
            
        # 4. ë©”íƒ€ë°ì´í„° ë¡œë“œ
        metadata_file = embeddings_path / "movie_metadata.jsonl"
        if metadata_file.exists():
            self.movie_metadata = []
            with open(metadata_file, 'r', encoding='utf-8') as f:
                for line in f:
                    self.movie_metadata.append(json.loads(line))
            print(f"ğŸ“‹ ì˜í™” ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(self.movie_metadata)}ê°œ")
        else:
            raise FileNotFoundError(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_file}")
            
        # 5. ì¥ë¥´ ì •ë³´ ë¡œë“œ
        genre_info_file = embeddings_path / "genre_info.json"
        if genre_info_file.exists():
            with open(genre_info_file, 'r', encoding='utf-8') as f:
                self.genre_info = json.load(f)
            print(f"ğŸ“Š ì¥ë¥´ ì •ë³´ ë¡œë“œ: {self.genre_info['dimension']}ê°œ ì¥ë¥´")
        
        # 6. FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        self._load_faiss_indices(embeddings_path)
        
        print(f"âœ… ëª¨ë“  ë¶„ë¦¬ëœ ì„ë² ë”© ë¡œë“œ ì™„ë£Œ!")
        
    def _load_faiss_indices(self, embeddings_path: Path):
        """FAISS ì¸ë±ìŠ¤ë“¤ ë¡œë“œ"""
        print("ğŸ” FAISS ì¸ë±ìŠ¤ ë¡œë”© ì¤‘...")
        
        # ì¤„ê±°ë¦¬ ì¸ë±ìŠ¤
        plot_index_file = embeddings_path / "plot_index.faiss"
        if plot_index_file.exists():
            self.plot_index = faiss.read_index(str(plot_index_file))
            print(f"ğŸ“ ì¤„ê±°ë¦¬ ì¸ë±ìŠ¤ ë¡œë“œ: {self.plot_index.ntotal}ê°œ ë²¡í„°")
        
        # íë¦„ê³¡ì„  ì¸ë±ìŠ¤
        flow_index_file = embeddings_path / "flow_index.faiss"
        if flow_index_file.exists():
            self.flow_index = faiss.read_index(str(flow_index_file))
            print(f"ğŸ“ˆ íë¦„ê³¡ì„  ì¸ë±ìŠ¤ ë¡œë“œ: {self.flow_index.ntotal}ê°œ ë²¡í„°")
        
        # ì¥ë¥´ ì¸ë±ìŠ¤
        genre_index_file = embeddings_path / "genre_index.faiss"
        if genre_index_file.exists():
            self.genre_index = faiss.read_index(str(genre_index_file))
            print(f"ğŸ­ ì¥ë¥´ ì¸ë±ìŠ¤ ë¡œë“œ: {self.genre_index.ntotal}ê°œ ë²¡í„°")
    
    def encode_query_text(self, query: str) -> np.ndarray:
        """ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ë¡œ ì„ë² ë”©"""
        embedding = self.sbert_model.encode([query], normalize_embeddings=True)[0]
        return embedding.astype(np.float32)
    
    def encode_query_flow(self, flow_description: str) -> np.ndarray:
        """
        íë¦„ ê´€ë ¨ ì¿¼ë¦¬ë¥¼ íë¦„ê³¡ì„  ë²¡í„°ë¡œ ë³€í™˜
        
        ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤í•‘ìœ¼ë¡œ ì‹œì‘:
        - "ê¸´ì¥ê°", "ìŠ¤ë¦´" -> ë†’ì€ ê°’
        - "ì”ì”í•œ", "í‰ì˜¨" -> ë‚®ì€ ê°’  
        - "ë³€í™”ë¬´ìŒ" -> ë³€ë™ì´ í° íŒ¨í„´
        """
        # ê¸°ë³¸ íë¦„ê³¡ì„  (ì¤‘ê°„ê°’ 5)
        base_flow = [5] * 20
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¡°ì •
        if any(word in flow_description for word in ["ê¸´ì¥", "ìŠ¤ë¦´", "ì•¡ì…˜"]):
            base_flow = [7, 8, 9, 8, 7, 8, 9, 8, 7, 8, 9, 7, 8, 9, 8, 7, 8, 9, 8, 7]
        elif any(word in flow_description for word in ["ì”ì”", "í‰ì˜¨", "ë“œë¼ë§ˆ"]):
            base_flow = [4, 3, 4, 3, 4, 3, 4, 5, 4, 3, 4, 3, 4, 5, 4, 3, 4, 3, 4, 3]
        elif any(word in flow_description for word in ["ë³€í™”", "ë°˜ì „", "ë¡¤ëŸ¬ì½”ìŠ¤í„°"]):
            base_flow = [2, 8, 3, 9, 1, 7, 4, 8, 2, 9, 3, 7, 1, 8, 4, 9, 2, 7, 3, 8]
        
        # 384ì°¨ì›ìœ¼ë¡œ í™•ì¥
        if len(base_flow) < 384:
            repeat_times = 384 // len(base_flow) + 1
            extended_flow = (base_flow * repeat_times)[:384]
        else:
            extended_flow = base_flow[:384]
        
        # ì •ê·œí™”
        normalized = np.array(extended_flow, dtype=float)
        normalized = (normalized - 5.0) / 5.0  # [-1, 1] ë²”ìœ„ë¡œ
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(normalized)
        if norm > 0:
            normalized = normalized / norm
            
        return normalized.astype(np.float32)
    
    def encode_query_genre(self, genre_description: str) -> np.ndarray:
        """
        ì¥ë¥´ ê´€ë ¨ ì¿¼ë¦¬ë¥¼ ì¥ë¥´ ë²¡í„°ë¡œ ë³€í™˜
        
        í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¥ë¥´ ì ìˆ˜ í• ë‹¹
        """
        if not self.genre_info:
            # ê¸°ë³¸ ì¥ë¥´ ë²¡í„°
            return np.zeros(384, dtype=np.float32)
        
        genre_types = self.genre_info['genre_types']
        genre_scores = {}
        
        # í‚¤ì›Œë“œ ë§¤í•‘
        genre_keywords = {
            'action': ['ì•¡ì…˜', 'ì „íˆ¬', 'ì‹¸ì›€', 'í­ë°œ', 'ì¶”ê²©'],
            'comedy': ['ì½”ë¯¸ë””', 'ì›ƒê¸´', 'ìœ ë¨¸', 'ì¬ë¯¸', 'ê°œê·¸'],
            'drama': ['ë“œë¼ë§ˆ', 'ê°ë™', 'ì¸ê°„', 'ì‚¶', 'ê°€ì¡±'],
            'horror': ['ê³µí¬', 'ë¬´ì„œìš´', 'ì¢€ë¹„', 'ê·€ì‹ ', 'ìŠ¤ë¦´ëŸ¬'],
            'romance': ['ë¡œë§¨ìŠ¤', 'ì‚¬ë‘', 'ì—°ì• ', 'ê²°í˜¼', 'ë¡œë§¨í‹±'],
            'sci_fi': ['SF', 'ë¯¸ë˜', 'ìš°ì£¼', 'ë¡œë´‡', 'ì¸ê³µì§€ëŠ¥', 'ê³¼í•™'],
            'thriller': ['ìŠ¤ë¦´ëŸ¬', 'ê¸´ì¥', 'ë¯¸ìŠ¤í„°ë¦¬', 'ë²”ì£„', 'ìˆ˜ì‚¬']
        }
        
        # ì¿¼ë¦¬ì—ì„œ ì¥ë¥´ ì¶”ì¶œ
        for genre, keywords in genre_keywords.items():
            if genre in genre_types:
                score = 0
                for keyword in keywords:
                    if keyword in genre_description:
                        score += 2
                genre_scores[genre] = min(score, 10)  # ìµœëŒ€ 10ì 
        
        # ê¸°ë³¸ ì¥ë¥´ ë²¡í„° ìƒì„±
        genre_vector = []
        for genre in genre_types:
            score = genre_scores.get(genre, 0)
            genre_vector.append(score)
        
        # 384ì°¨ì›ìœ¼ë¡œ í™•ì¥
        if len(genre_vector) < 384:
            genre_vector.extend([0] * (384 - len(genre_vector)))
        else:
            genre_vector = genre_vector[:384]
        
        # ì •ê·œí™”
        normalized = np.array(genre_vector, dtype=float)
        normalized = (normalized - 5.0) / 5.0  # [-1, 1] ë²”ìœ„ë¡œ
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(normalized)
        if norm > 0:
            normalized = normalized / norm
            
        return normalized.astype(np.float32)
    
    def search_with_flexible_weights(
        self, 
        query: str,
        w_plot: float = None,
        w_flow: float = None, 
        w_genre: float = None,
        top_k: int = 20,
        flow_hint: str = "",
        genre_hint: str = ""
    ) -> List[Dict[str, Any]]:
        """
        ì‚¬ìš©ì ì§€ì • ê°€ì¤‘ì¹˜ë¡œ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            query: ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬
            w_plot: ì¤„ê±°ë¦¬ ê°€ì¤‘ì¹˜ (0~1)
            w_flow: íë¦„ê³¡ì„  ê°€ì¤‘ì¹˜ (0~1) 
            w_genre: ì¥ë¥´ ê°€ì¤‘ì¹˜ (0~1)
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            flow_hint: íë¦„ ê´€ë ¨ íŒíŠ¸ ("ê¸´ì¥ê° ìˆëŠ”", "ì”ì”í•œ" ë“±)
            genre_hint: ì¥ë¥´ ê´€ë ¨ íŒíŠ¸ ("ì•¡ì…˜", "ë¡œë§¨ìŠ¤" ë“±)
        """
        
        if not all([self.plot_embeddings is not None, 
                   self.flow_embeddings is not None,
                   self.genre_embeddings is not None]):
            raise ValueError("ë¶„ë¦¬ëœ ì„ë² ë”©ë“¤ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_separated_embeddings()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        if all(w is None for w in [w_plot, w_flow, w_genre]):
            w_plot, w_flow, w_genre = self.default_weights['plot'], self.default_weights['flow'], self.default_weights['genre']
        else:
            # ì…ë ¥ëœ ê°€ì¤‘ì¹˜ë“¤ì˜ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”
            weights = np.array([w_plot or 0, w_flow or 0, w_genre or 0])
            if weights.sum() > 0:
                weights = weights / weights.sum()
                w_plot, w_flow, w_genre = weights
            else:
                w_plot, w_flow, w_genre = self.default_weights['plot'], self.default_weights['flow'], self.default_weights['genre']
        
        print(f"ğŸ” ê²€ìƒ‰ ì‹¤í–‰: plot={w_plot:.2f}, flow={w_flow:.2f}, genre={w_genre:.2f}")
        
        # ê° ëª¨ë‹¬ë¦¬í‹°ë³„ ì¿¼ë¦¬ ì„ë² ë”©
        query_plot = self.encode_query_text(query)
        query_flow = self.encode_query_flow(flow_hint or query)
        query_genre = self.encode_query_genre(genre_hint or query)
        
        # ê° ëª¨ë‹¬ë¦¬í‹°ë³„ ìœ ì‚¬ë„ ê³„ì‚°
        plot_scores = np.dot(self.plot_embeddings, query_plot)
        flow_scores = np.dot(self.flow_embeddings, query_flow) 
        genre_scores = np.dot(self.genre_embeddings, query_genre)
        
        # ê°€ì¤‘í•© ê³„ì‚°
        final_scores = (w_plot * plot_scores + 
                       w_flow * flow_scores + 
                       w_genre * genre_scores)
        
        # ìƒìœ„ Kê°œ ê²°ê³¼ ì„ íƒ
        top_indices = np.argsort(final_scores)[::-1][:top_k]
        
        # ê²°ê³¼ í¬ë§·íŒ…
        results = []
        for i, idx in enumerate(top_indices):
            movie_meta = self.movie_metadata[idx]
            result = {
                'rank': i + 1,
                'movie_id': movie_meta['movie_id'],
                'title': movie_meta['title'],
                'year': movie_meta.get('year', ''),
                'director': movie_meta.get('director', ''),
                'final_score': float(final_scores[idx]),
                'component_scores': {
                    'plot': float(plot_scores[idx]), 
                    'flow': float(flow_scores[idx]),
                    'genre': float(genre_scores[idx])
                },
                'weights_used': {
                    'plot': w_plot,
                    'flow': w_flow, 
                    'genre': w_genre
                }
            }
            results.append(result)
        return results
    
    def print_search_results(self, results: List[Dict[str, Any]], query: str):
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
        print(f"\nğŸ” ê²€ìƒ‰ ê²°ê³¼: '{query}'")
        print("=" * 80)
        
        for result in results:
            print(f"\nğŸ¬ ìˆœìœ„ {result['rank']}: {result['title']} ({result['year']})")
            print(f"   ê°ë…: {result['director']}")
            print(f"   ğŸ”¢ ìµœì¢… ì ìˆ˜: {result['final_score']:.4f}")
            print(f"   ğŸ“Š ì„¸ë¶€ ì ìˆ˜: ì¤„ê±°ë¦¬={result['component_scores']['plot']:.3f}, "
                  f"íë¦„={result['component_scores']['flow']:.3f}, "
                  f"ì¥ë¥´={result['component_scores']['genre']:.3f}")
            print(f"   âš–ï¸ ì‚¬ìš©ëœ ê°€ì¤‘ì¹˜: ì¤„ê±°ë¦¬={result['weights_used']['plot']:.2f}, "
                  f"íë¦„={result['weights_used']['flow']:.2f}, "
                  f"ì¥ë¥´={result['weights_used']['genre']:.2f}")


def demonstrate_flexible_search():
    """ìœ ì—°í•œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ë°ëª¨"""
    print("ğŸ­ íŒŒì¸íŠœë‹ëœ ë¶„ë¦¬ ì„ë² ë”© ê²€ìƒ‰ ì‹œìŠ¤í…œ ë°ëª¨")
    print("=" * 60)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = FlexibleMultimodalSystem()
    
    # ë¶„ë¦¬ëœ ì„ë² ë”© ë¡œë“œ
    system.load_separated_embeddings()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        {
            'query': 'ê¿ˆê³¼ í˜„ì‹¤ì„ ì˜¤ê°€ëŠ” ì˜í™”',
            'flow_hint': 'ì‹¬ë¦¬ì  ê¸´ì¥ê°',
            'genre_hint': 'SF ìŠ¤ë¦´ëŸ¬',
            'weights': [
                {'plot': 0.8, 'flow': 0.1, 'genre': 0.1, 'name': 'ì¤„ê±°ë¦¬ ì¤‘ì‹¬'},
                {'plot': 0.4, 'flow': 0.4, 'genre': 0.2, 'name': 'íë¦„ ì¤‘ì‹œ'},
                {'plot': 0.3, 'flow': 0.2, 'genre': 0.5, 'name': 'ì¥ë¥´ ì¤‘ì‹¬'}
            ]
        },
        {
            'query': 'ì¢€ë¹„ ì•„í¬ì¹¼ë¦½ìŠ¤ ìƒì¡´',
            'flow_hint': 'ê¸´ì¥ê° ë„˜ì¹˜ëŠ” ì•¡ì…˜',
            'genre_hint': 'ê³µí¬ ì•¡ì…˜',
            'weights': [
                {'plot': 0.6, 'flow': 0.3, 'genre': 0.1, 'name': 'ê¸°ë³¸ ê· í˜•'},
                {'plot': 0.2, 'flow': 0.6, 'genre': 0.2, 'name': 'íë¦„ ì¤‘ì‹¬'}
            ]
        }
    ]
    
    # ê° ì¿¼ë¦¬ë³„ í…ŒìŠ¤íŠ¸
    for test in test_queries:
        for weight_config in test['weights']:
            print(f"\n{'='*80}")
            print(f"ğŸ” ì¿¼ë¦¬: {test['query']}")
            print(f"âš–ï¸ ê°€ì¤‘ì¹˜ ì„¤ì •: {weight_config['name']}")
            print(f"ğŸ“ íë¦„ íŒíŠ¸: {test['flow_hint']}")
            print(f"ğŸ­ ì¥ë¥´ íŒíŠ¸: {test['genre_hint']}")
            
            results = system.search_with_flexible_weights(
                query=test['query'],
                w_plot=weight_config['plot'],
                w_flow=weight_config['flow'],
                w_genre=weight_config['genre'],
                top_k=10,
                flow_hint=test['flow_hint'],
                genre_hint=test['genre_hint']
            )
            
            system.print_search_results(results[:5], test['query'])  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
            
            print(f"\nğŸ’¡ ë¶„ì„: {weight_config['name']} ì„¤ì •ìœ¼ë¡œ ê²€ìƒ‰")
            time.sleep(1)  # ì¶œë ¥ ê°„ê²©


def interactive_search():
    """ëŒ€í™”í˜• ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤"""
    print("ğŸ® ëŒ€í™”í˜• ìœ ì—° ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    system = FlexibleMultimodalSystem()
    system.load_separated_embeddings()
    
    print("\nğŸ“– ì‚¬ìš©ë²•:")
    print("- ê²€ìƒ‰ì–´ ì…ë ¥ (ì˜ˆ: 'ê¿ˆê³¼ í˜„ì‹¤ì„ ì˜¤ê°€ëŠ” ì˜í™”')")
    print("- ê°€ì¤‘ì¹˜ëŠ” 0-1 ì‚¬ì´ ê°’ìœ¼ë¡œ ì…ë ¥ (ë¹ˆì¹¸ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)")
    print("- 'quit' ì…ë ¥ì‹œ ì¢…ë£Œ")
    
    while True:
        try:
            print(f"\n{'='*50}")
            query = input("ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if query.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
                
            if not query:
                print("âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            # ê°€ì¤‘ì¹˜ ì…ë ¥
            print("\nâš–ï¸ ê°€ì¤‘ì¹˜ ì„¤ì • (ì—”í„°í‚¤ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©):")
            
            w_plot_input = input(f"  ğŸ“ ì¤„ê±°ë¦¬ ê°€ì¤‘ì¹˜ [ê¸°ë³¸ê°’: {system.default_weights['plot']}]: ").strip()
            w_plot = float(w_plot_input) if w_plot_input else system.default_weights['plot']
            
            w_flow_input = input(f"  ğŸ“ˆ íë¦„ê³¡ì„  ê°€ì¤‘ì¹˜ [ê¸°ë³¸ê°’: {system.default_weights['flow']}]: ").strip()
            w_flow = float(w_flow_input) if w_flow_input else system.default_weights['flow']
            
            w_genre_input = input(f"  ğŸ­ ì¥ë¥´ ê°€ì¤‘ì¹˜ [ê¸°ë³¸ê°’: {system.default_weights['genre']}]: ").strip()
            w_genre = float(w_genre_input) if w_genre_input else system.default_weights['genre']
            
            # íŒíŠ¸ ì…ë ¥
            flow_hint = input("  ğŸ“ˆ íë¦„ íŒíŠ¸ (ì„ íƒì‚¬í•­): ").strip()
            genre_hint = input("  ğŸ­ ì¥ë¥´ íŒíŠ¸ (ì„ íƒì‚¬í•­): ").strip()
            
            # ê²€ìƒ‰ ì‹¤í–‰
            results = system.search_with_flexible_weights(
                query=query,
                w_plot=w_plot,
                w_flow=w_flow, 
                w_genre=w_genre,
                top_k=15,
                flow_hint=flow_hint,
                genre_hint=genre_hint
            )
            
            system.print_search_results(results[:10], query)
            
        except KeyboardInterrupt:
            print(f"\n\nğŸ‘‹ ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except ValueError as e:
            print(f"âŒ ê°€ì¤‘ì¹˜ ì…ë ¥ ì˜¤ë¥˜: {e}")
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == '--demo':
        demonstrate_flexible_search()
    elif len(sys.argv) > 1 and sys.argv[1] == '--interactive':
        interactive_search()
    else:
        print("ğŸ­ íŒŒì¸íŠœë‹ëœ ë¶„ë¦¬ ì„ë² ë”© ê²€ìƒ‰ ì‹œìŠ¤í…œ")
        print("=" * 60)
        print("ğŸ“– ì‚¬ìš©ë²•:")
        print("  python flexible_multimodal_system.py --demo       # ë°ëª¨ ì‹¤í–‰")
        print("  python flexible_multimodal_system.py --interactive # ëŒ€í™”í˜• ì‹¤í–‰")
        print("\nğŸ’¡ ë˜ëŠ” ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©:")
        print("  system = FlexibleMultimodalSystem()")
        print("  system.load_separated_embeddings()")
        print("  results = system.search_with_flexible_weights(query='ì›í•˜ëŠ” ê²€ìƒ‰ì–´', w_plot=0.6, w_flow=0.3, w_genre=0.1)")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        try:
            system = FlexibleMultimodalSystem()
            system.load_separated_embeddings()
            
            print(f"\nâœ… ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!")
            print(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°: {len(system.movie_metadata)}ê°œ ì˜í™”")
            print(f"ğŸ“ ì¤„ê±°ë¦¬ ì„ë² ë”©: {system.plot_embeddings.shape}")
            print(f"ğŸ“ˆ íë¦„ê³¡ì„  ì„ë² ë”©: {system.flow_embeddings.shape}")
            print(f"ğŸ­ ì¥ë¥´ ì„ë² ë”©: {system.genre_embeddings.shape}")
            
            # ê°„ë‹¨í•œ ê²€ìƒ‰ ì˜ˆì‹œ
            print(f"\nğŸ” ê°„ë‹¨í•œ ê²€ìƒ‰ ì˜ˆì‹œ:")
            results = system.search_with_flexible_weights(
                query="ê¿ˆê³¼ í˜„ì‹¤ì„ ì˜¤ê°€ëŠ” ì˜í™”",
                w_plot=0.7, w_flow=0.2, w_genre=0.1,
                top_k=3
            )
            
            for result in results:
                print(f"  ğŸ¬ {result['title']} (ì ìˆ˜: {result['final_score']:.3f})")
                
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ë¨¼ì € generate_separated_embeddings.pyë¥¼ ì‹¤í–‰í•´ì„œ ë¶„ë¦¬ëœ ì„ë² ë”©ì„ ìƒì„±í•˜ì„¸ìš”.")
        
        # ì²­í‚¹ëœ ë°ì´í„°ë¥¼ ì˜í™”ë³„ë¡œ ê·¸ë£¹í™”
        print("ğŸ“‹ ê¸°ì¡´ ì²­í‚¹ ë°ì´í„° ë¡œë”©...")
        movie_chunks = {}
        with open(chunk_metadata_file, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                meta = json.loads(line)
                movie_id = (meta['title'], meta['year'])
                if movie_id not in movie_chunks:
                    movie_chunks[movie_id] = []
                movie_chunks[movie_id].append((i, chunk_embeddings[i]))
        
        print(f"ğŸ“Š ì´ {len(movies)}ê°œ ì˜í™” ë°œê²¬, {len(movie_chunks)}ê°œ ì˜í™”ì˜ ì²­í‚¹ ë°ì´í„° ì‚¬ìš© ê°€ëŠ¥")
        
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        plot_embeddings = []
        flow_embeddings = []
        genre_embeddings = []
        movie_metadata = []
        
        print("\nğŸ”„ ë¶„ë¦¬ëœ ì„ë² ë”© ìƒì„± ì¤‘...")
        start_time = time.time()
        chunk_used = 0
        new_generated = 0
        
        for i, movie in enumerate(movies):
            try:
                if (i + 1) % 50 == 0 or i + 1 == len(movies):
                    elapsed = time.time() - start_time
                    print(f"   [{i+1:3d}/{len(movies)}] {movie.get('title', 'Unknown')} ({elapsed:.1f}ì´ˆ)")
                
                # 1. ì¤„ê±°ë¦¬ ì„ë² ë”© (ê¸°ì¡´ ì²­í‚¹ ë°ì´í„° ìš°ì„  ì‚¬ìš©)
                movie_id = (movie.get('title', 'Unknown'), movie.get('year', 'Unknown'))
                if movie_id in movie_chunks:
                    # ê¸°ì¡´ ì²­í‚¹ëœ ì„ë² ë”©ë“¤ì˜ í‰ê·  ì‚¬ìš©
                    chunk_embeds = [emb for _, emb in movie_chunks[movie_id]]
                    plot_emb = np.mean(chunk_embeds, axis=0).astype('float32')
                    chunk_used += 1
                else:
                    # ì²­í‚¹ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒˆë¡œ ìƒì„±
                    plot_emb = self._get_plot_embedding(movie['plot'])
                    new_generated += 1
                plot_embeddings.append(plot_emb)
                
                # 2. íë¦„ê³¡ì„  ì„ë² ë”©
                flow_emb = self._get_flow_embedding(movie['flow_curve'])
                flow_embeddings.append(flow_emb)
                
                # 3. ì¥ë¥´ ì„ë² ë”©
                genre_emb = self._get_genre_embedding(movie['genres'])
                genre_embeddings.append(genre_emb)
                
                # ë©”íƒ€ë°ì´í„°
                metadata = {
                    'movie_index': i,
                    'title': movie.get('title', 'Unknown'),
                    'year': movie.get('year', 'Unknown'),
                    'director': movie.get('director', 'Unknown'),
                    'plot': movie.get('plot', ''),
                    'flow_curve': movie.get('flow_curve', []),
                    'genres': movie.get('genres', {}),
                    'poster': movie.get('poster', '')
                }
                movie_metadata.append(metadata)
                
            except Exception as e:
                print(f"âš ï¸ ì˜¤ë¥˜ - {movie.get('title', 'Unknown')}: {e}")
                continue
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        plot_array = np.vstack(plot_embeddings).astype('float32')
        flow_array = np.vstack(flow_embeddings).astype('float32') 
        genre_array = np.vstack(genre_embeddings).astype('float32')
        
        # ë¶„ë¦¬ëœ íŒŒì¼ë¡œ ì €ì¥
        np.save(output_path / 'plot_embeddings.npy', plot_array)
        np.save(output_path / 'flow_embeddings.npy', flow_array)
        np.save(output_path / 'genre_embeddings.npy', genre_array)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        with open(output_path / 'flexible_metadata.jsonl', 'w', encoding='utf-8') as f:
            for meta in movie_metadata:
                f.write(json.dumps(meta, ensure_ascii=False) + '\\n')
        
        print(f"\\nâœ… ë¶„ë¦¬ëœ ì„ë² ë”© ì €ì¥ ì™„ë£Œ!")
        print(f"   ğŸ“ ì¤„ê±°ë¦¬: {output_path / 'plot_embeddings.npy'} ({plot_array.shape})")
        print(f"   ğŸ“ íë¦„ê³¡ì„ : {output_path / 'flow_embeddings.npy'} ({flow_array.shape})")
        print(f"   ğŸ“ ì¥ë¥´: {output_path / 'genre_embeddings.npy'} ({genre_array.shape})")
        print(f"   ğŸ“ ë©”íƒ€ë°ì´í„°: {output_path / 'flexible_metadata.jsonl'}")
        print(f"\\nğŸ“Š ì¤„ê±°ë¦¬ ì„ë² ë”© í†µê³„:")
        print(f"   â€¢ ê¸°ì¡´ ì²­í‚¹ ë°ì´í„° ì‚¬ìš©: {chunk_used}ê°œ")
        print(f"   â€¢ ìƒˆë¡œ ìƒì„±: {new_generated}ê°œ")
        print(f"   â€¢ ì´ ì²˜ë¦¬: {len(plot_embeddings)}ê°œ")
        print(f"   ğŸ“ ë©”íƒ€ë°ì´í„°: {output_path / 'flexible_metadata.jsonl'}")
        
        return plot_array, flow_array, genre_array, movie_metadata
    
    def load_separate_embeddings(self, data_dir: str = "data"):
        """ë¶„ë¦¬ëœ ì„ë² ë”©ë“¤ ë¡œë“œ"""
        data_path = Path(data_dir)
        
        self.plot_embeddings = np.load(data_path / 'plot_embeddings.npy')
        self.flow_embeddings = np.load(data_path / 'flow_embeddings.npy')
        self.genre_embeddings = np.load(data_path / 'genre_embeddings.npy')
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.metadata = []
        with open(data_path / 'flexible_metadata.jsonl', 'r', encoding='utf-8') as f:
            for line in f:
                self.metadata.append(json.loads(line))
        
        print(f"ğŸ“ ë¶„ë¦¬ëœ ì„ë² ë”© ë¡œë“œ ì™„ë£Œ:")
        print(f"   ì¤„ê±°ë¦¬: {self.plot_embeddings.shape}")
        print(f"   íë¦„ê³¡ì„ : {self.flow_embeddings.shape}")
        print(f"   ì¥ë¥´: {self.genre_embeddings.shape}")
        
    def combine_embeddings_with_weights(self, plot_weight: float, flow_weight: float, genre_weight: float) -> np.ndarray:
        """ì‚¬ìš©ì ì§€ì • ê°€ì¤‘ì¹˜ë¡œ ì„ë² ë”© ê²°í•©"""
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = plot_weight + flow_weight + genre_weight
        plot_w = plot_weight / total_weight
        flow_w = flow_weight / total_weight  
        genre_w = genre_weight / total_weight
        
        print(f"âš–ï¸ ê°€ì¤‘ì¹˜: ì¤„ê±°ë¦¬({plot_w:.2f}) + íë¦„ê³¡ì„ ({flow_w:.2f}) + ì¥ë¥´({genre_w:.2f})")
        
        # ì‹¤ì‹œê°„ ê²°í•©
        combined = (
            self.plot_embeddings * plot_w +
            self.flow_embeddings * flow_w +
            self.genre_embeddings * genre_w
        )
        
        # L2 ì •ê·œí™”
        norms = np.linalg.norm(combined, axis=1, keepdims=True)
        norms[norms == 0] = 1  # 0 ë‚˜ëˆ„ê¸° ë°©ì§€
        combined = combined / norms
        
        return combined.astype('float32')
    
    def find_similar_movies_flexible(self, movie_title: str, movie_year: str = None,
                                   plot_weight: float = 0.65, flow_weight: float = 0.25, genre_weight: float = 0.10,
                                   top_k: int = 10) -> List[Dict[str, Any]]:
        """ì‚¬ìš©ì ì§€ì • ê°€ì¤‘ì¹˜ë¡œ ìœ ì‚¬ ì˜í™” ê²€ìƒ‰"""
        
        # ëŒ€ìƒ ì˜í™” ì°¾ê¸°
        target_index = self._find_movie_index(movie_title, movie_year)
        if target_index is None:
            raise ValueError(f"ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {movie_title}")
        
        print(f"ğŸ¯ ëŒ€ìƒ ì˜í™”: {self.metadata[target_index]['title']} ({self.metadata[target_index]['year']})")
        
        # ì‚¬ìš©ì ì§€ì • ê°€ì¤‘ì¹˜ë¡œ ëª¨ë“  ì„ë² ë”© ê²°í•©
        combined_embeddings = self.combine_embeddings_with_weights(plot_weight, flow_weight, genre_weight)
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„± (ì‹¤ì‹œê°„)
        index = faiss.IndexFlatIP(self.embedding_dim)
        index.add(combined_embeddings)
        
        # ëŒ€ìƒ ì˜í™”ì˜ ê²°í•© ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰
        query_vector = combined_embeddings[target_index:target_index+1]
        similarities, indices = index.search(query_vector, top_k + 1)  # +1 for excluding self
        
        # ê²°ê³¼ ì •ë¦¬
        similar_movies = []
        for sim, idx in zip(similarities[0], indices[0]):
            if idx == target_index:  # ìê¸° ìì‹  ì œì™¸
                continue
            
            if len(similar_movies) >= top_k:
                break
                
            movie_meta = self.metadata[idx]
            similar_movies.append({
                'rank': len(similar_movies) + 1,
                'title': movie_meta['title'],
                'year': movie_meta['year'], 
                'director': movie_meta['director'],
                'similarity_score': float(sim),
                'genres': movie_meta['genres'],
                'flow_curve': movie_meta['flow_curve'],
                'plot': movie_meta['plot'][:200] + "..." if len(movie_meta['plot']) > 200 else movie_meta['plot'],
                'poster': movie_meta['poster']
            })
        
        return similar_movies
    
    def _find_movie_index(self, title: str, year: str = None) -> int:
        """ì˜í™” ì¸ë±ìŠ¤ ì°¾ê¸°"""
        for i, meta in enumerate(self.metadata):
            if title.lower() in meta['title'].lower():
                if year is None or meta['year'] == year:
                    return i
        return None
    
    # ê¸°ì¡´ ì„ë² ë”© ìƒì„± ë©”ì„œë“œë“¤ (create_multimodal_embeddings.pyì—ì„œ ë³µì‚¬)
    def _split_sentences(self, text: str) -> List[str]:
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        return sentences
    
    def _create_plot_chunks(self, plot: str, window_size: int = 2, stride: int = 1) -> List[str]:
        sentences = self._split_sentences(plot)
        
        if len(sentences) <= window_size:
            return [plot]
        
        chunks = []
        for i in range(0, len(sentences) - window_size + 1, stride):
            chunk = ' '.join(sentences[i:i + window_size])
            chunks.append(chunk)
        
        return chunks
    
    def _get_plot_embedding(self, plot: str) -> np.ndarray:
        chunks = self._create_plot_chunks(plot)
        
        with torch.inference_mode():
            chunk_embeddings = self.sbert_model.encode(
                chunks, convert_to_numpy=True, normalize_embeddings=True
            )
        
        movie_plot_embedding = np.mean(chunk_embeddings, axis=0)
        
        norm = np.linalg.norm(movie_plot_embedding)
        if norm > 0:
            movie_plot_embedding = movie_plot_embedding / norm
            
        return movie_plot_embedding.astype('float32')
    
    def _get_flow_embedding(self, flow_curve: List[float]) -> np.ndarray:
        flow_array = np.array(flow_curve, dtype='float32')
        flow_normalized = flow_array / 10.0
        
        expanded_flow = np.tile(flow_normalized, 38)
        avg_flow = np.mean(flow_normalized) 
        flow_padding = np.full(4, avg_flow, dtype='float32')
        
        flow_embedding = np.concatenate([expanded_flow, flow_padding])
        
        norm = np.linalg.norm(flow_embedding)
        if norm > 0:
            flow_embedding = flow_embedding / norm
            
        return flow_embedding
    
    def _get_genre_embedding(self, genres: Dict[str, int]) -> np.ndarray:
        genre_names = ['action', 'thriller', 'romance', 'drama', 'comedy', 'sci_fi', 'horror']
        
        genre_scores = []
        for genre in genre_names:
            score = genres.get(genre, 0) / 10.0
            genre_scores.append(score)
        
        genre_array = np.array(genre_scores, dtype='float32')
        
        expanded_genre = np.tile(genre_array, 54)
        avg_genre = np.mean(genre_array)
        genre_padding = np.full(6, avg_genre, dtype='float32')
        
        genre_embedding = np.concatenate([expanded_genre, genre_padding])
        
        norm = np.linalg.norm(genre_embedding)
        if norm > 0:
            genre_embedding = genre_embedding / norm
            
        return genre_embedding

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ìœ ì—°í•œ ë©€í‹°ëª¨ë‹¬ ì˜í™” ì¶”ì²œ")
    parser.add_argument('--build', action='store_true', help='ë¶„ë¦¬ëœ ì„ë² ë”© ìƒì„±')
    parser.add_argument('--movie', type=str, help='ê²€ìƒ‰í•  ì˜í™” ì œëª©')
    parser.add_argument('--year', type=str, help='ì˜í™” ì—°ë„')
    parser.add_argument('--plot_weight', type=float, default=0.65, help='ì¤„ê±°ë¦¬ ê°€ì¤‘ì¹˜')
    parser.add_argument('--flow_weight', type=float, default=0.25, help='íë¦„ê³¡ì„  ê°€ì¤‘ì¹˜')
    parser.add_argument('--genre_weight', type=float, default=0.10, help='ì¥ë¥´ ê°€ì¤‘ì¹˜')
    parser.add_argument('--top_k', type=int, default=10, help='ì¶”ì²œ ì˜í™” ìˆ˜')
    
    args = parser.parse_args()
    
    try:
        system = FlexibleMultimodalSystem()
        
        if args.build:
            # ë¶„ë¦¬ëœ ì„ë² ë”© ìƒì„±
            input_file = "data/processed/movies_dataset.json"
            system.create_separate_embeddings(input_file)
        else:
            # ì„ë² ë”© ë¡œë“œ
            system.load_separate_embeddings()
            
            if args.movie:
                # ë‹¨ì¼ ê²€ìƒ‰
                similar_movies = system.find_similar_movies_flexible(
                    args.movie, args.year,
                    args.plot_weight, args.flow_weight, args.genre_weight,
                    args.top_k
                )
                
                # ê²°ê³¼ ì¶œë ¥
                print(f"\\nğŸ¬ '{args.movie}'ì™€ ìœ ì‚¬í•œ ì˜í™”ë“¤ (ê°€ì¤‘ì¹˜ ì¡°ì •)")
                print("=" * 80)
                
                for movie in similar_movies:
                    print(f"\\n{movie['rank']:2d}. {movie['title']} ({movie['year']})")
                    print(f"    ê°ë…: {movie['director']}")
                    print(f"    ìœ ì‚¬ë„: {movie['similarity_score']:.3f}")
            else:
                # ëŒ€í™”í˜• ëª¨ë“œ
                print("\\nğŸ¬ ìœ ì—°í•œ ë©€í‹°ëª¨ë‹¬ ì¶”ì²œ ì‹œìŠ¤í…œ")
                print("=" * 50)
                print("â€¢ ê°€ì¤‘ì¹˜ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                print("â€¢ 'quit' ì…ë ¥ì‹œ ì¢…ë£Œ")
                print("=" * 50)
                
                while True:
                    try:
                        movie_title = input("\\nğŸ” ì˜í™” ì œëª© > ").strip()
                        if movie_title.lower() in ['quit', 'exit']:
                            break
                        
                        # ê°€ì¤‘ì¹˜ ì…ë ¥
                        print("ê°€ì¤‘ì¹˜ ì…ë ¥ (ê¸°ë³¸ê°’: ì¤„ê±°ë¦¬ 0.65, íë¦„ê³¡ì„  0.25, ì¥ë¥´ 0.10)")
                        plot_w = float(input("ì¤„ê±°ë¦¬ ê°€ì¤‘ì¹˜ > ") or "0.65")
                        flow_w = float(input("íë¦„ê³¡ì„  ê°€ì¤‘ì¹˜ > ") or "0.25") 
                        genre_w = float(input("ì¥ë¥´ ê°€ì¤‘ì¹˜ > ") or "0.10")
                        
                        similar_movies = system.find_similar_movies_flexible(
                            movie_title, None, plot_w, flow_w, genre_w, 5
                        )
                        
                        # ê²°ê³¼ ì¶œë ¥
                        print(f"\\nğŸ¬ '{movie_title}'ì™€ ìœ ì‚¬í•œ ì˜í™”ë“¤")
                        for movie in similar_movies:
                            print(f"{movie['rank']}. {movie['title']} ({movie['year']}) - {movie['similarity_score']:.3f}")
                        
                    except Exception as e:
                        print(f"âŒ ì˜¤ë¥˜: {e}")
                    except KeyboardInterrupt:
                        break
    
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()