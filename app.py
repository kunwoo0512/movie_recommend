#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Flask Web Application for Movie Recommendation System
"""

from flask import Flask, render_template, request, jsonify, Response, stream_with_context
import os
import json
import subprocess
import sys
import signal
import atexit
import numpy as np
import faiss
from pathlib import Path
from dotenv import load_dotenv
import time
import threading
from queue import Queue

# build_faiss_and_query.pyì˜ ê¸°ì¡´ í•¨ìˆ˜ë“¤ import
from build_faiss_and_query import (
    load_metadata, 
    ensure_unit_norm,
    query_index, 
    aggregate_by_movie,
    LLMMovieFilter,
    format_results_for_web
)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê¸€ë¡œë²Œ ëª¨ë¸ ë³€ìˆ˜ë“¤ (ì„œë²„ ì‹œì‘ì‹œ ë¡œë”©)
global_index = None
global_metadata = None
global_models_loaded = False
global_sentence_model = None  # ì„ë² ë”© ëª¨ë¸ ì‚¬ì „ ë¡œë”©

def load_models_on_startup():
    """ì„œë²„ ì‹œì‘ì‹œ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì‚¬ì „ ë¡œë”©"""
    global global_index, global_metadata, global_models_loaded, global_sentence_model
    
    print("ğŸ”„ [ì‹œì‘] ëª¨ë¸ ë° ë°ì´í„° ì‚¬ì „ ë¡œë”© ì¤‘...")
    start_time = time.time()
    
    try:
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ (build_faiss_and_query.py í•¨ìˆ˜ ì‚¬ìš©)
        index_path = Path('data/index.faiss')
        if index_path.exists():
            import faiss
            global_index = faiss.read_index(str(index_path))
            print(f"âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {global_index.ntotal}ê°œ ë²¡í„°")
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ (build_faiss_and_query.py í•¨ìˆ˜ ì‚¬ìš©)
        metadata_path = Path('data/metadata.jsonl')
        if metadata_path.exists():
            global_metadata = load_metadata(metadata_path)  # build_faiss_and_query.py í•¨ìˆ˜ ì‚¬ìš©
            print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(global_metadata)}ê°œ ì˜í™”")
        
        # ì„ë² ë”© ëª¨ë¸ë„ ì„œë²„ ì‹œì‘ ì‹œ ë¯¸ë¦¬ ë¡œë”©
        from sentence_transformers import SentenceTransformer
        import torch
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... (device: {device})")
        global_sentence_model = SentenceTransformer(
            'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
            device=device
        )
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        global_models_loaded = True
        load_time = time.time() - start_time
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ (ì„ íƒì )
        try:
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            print(f"ğŸ’¾ í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.1f}MB")
        except ImportError:
            print("ğŸ’¾ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•´ 'pip install psutil' ì‹¤í–‰ ê°€ëŠ¥")
        except Exception as e:
            print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì²´í¬ ì˜¤ë¥˜: {e}")
            
        print(f"ğŸ‰ [ì™„ë£Œ] ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì™„ë£Œ! ({load_time:.2f}ì´ˆ)")
        
    except Exception as e:
        print(f"âŒ [ì˜¤ë¥˜] ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        global_models_loaded = False

# í™œì„± í”„ë¡œì„¸ìŠ¤ë“¤ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸ (ê°„ë‹¨í•œ ë²„ì „)
active_processes = []

def cleanup_on_exit():
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ë‚¨ì€ í”„ë¡œì„¸ìŠ¤ë“¤ ì •ë¦¬"""
    global active_processes
    for process in active_processes[:]:  # ë³µì‚¬ë³¸ìœ¼ë¡œ ìˆœíšŒ
        try:
            if process.poll() is None:  # ì•„ì§ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤
                print(f"ğŸ§¹ ì •ë¦¬ ì¤‘: PID {process.pid}")
                process.terminate()
                try:
                    process.wait(timeout=3)  # 3ì´ˆ ëŒ€ê¸°
                except subprocess.TimeoutExpired:
                    process.kill()  # ê°•ì œ ì¢…ë£Œ
            active_processes.remove(process)
        except Exception as e:
            print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì˜¤ë¥˜: {e}")

# í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ì •ë¦¬ í•¨ìˆ˜ ë“±ë¡
atexit.register(cleanup_on_exit)

# Ctrl+C ì²˜ë¦¬
def signal_handler(signum, frame):
    print(f"\nğŸ›‘ ì¢…ë£Œ ì‹œê·¸ë„ ìˆ˜ì‹  - ì •ë¦¬ ì¤‘...")
    cleanup_on_exit()
    sys.exit(0)

if hasattr(signal, 'SIGINT'):
    signal.signal(signal.SIGINT, signal_handler)

app = Flask(__name__)

# ì •ì  íŒŒì¼ ì„¤ì •
app.static_folder = 'static'
app.template_folder = 'templates'

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    print("ğŸ  [DEBUG] ë©”ì¸ í˜ì´ì§€ ì ‘ì†!")
    
    # ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì§€ê¸ˆ ë¡œë”©
    if not global_models_loaded:
        print("ğŸ“š [DEBUG] ëª¨ë¸ì´ ì•„ì§ ë¡œë”©ë˜ì§€ ì•ŠìŒ - ì§€ê¸ˆ ë¡œë”©í•©ë‹ˆë‹¤")
        load_models_on_startup()
    else:
        print("âœ… [DEBUG] ëª¨ë¸ì´ ì´ë¯¸ ë¡œë”©ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
    
    return render_template('index.html')

@app.route('/search', methods=['POST'])
def search_movies():
    """ì˜í™” ê²€ìƒ‰ API"""
    print("ğŸ”¥ [DEBUG] /search ì—”ë“œí¬ì¸íŠ¸ ì§„ì…!")
    try:
        print("ğŸ”¥ [DEBUG] ìš”ì²­ ë°ì´í„° íŒŒì‹± ì‹œì‘")
        data = request.get_json()
        query = data.get('query', '').strip()
        print(f"ğŸ”¥ [DEBUG] ë°›ì€ ê²€ìƒ‰ì–´: '{query}'")
        
        if not query:
            print("ğŸ”¥ [DEBUG] ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ìˆìŒ")
            return jsonify({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400
        
        # build_faiss_and_query.py ì‹¤í–‰
        print(f"[ê²€ìƒ‰] '{query}' ê²€ìƒ‰ ì‹œì‘...")
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
        openai_key = os.getenv('OPENAI_API_KEY')
        print(f"ğŸ”¥ [DEBUG] OPENAI_API_KEY ì¡´ì¬ ì—¬ë¶€: {bool(openai_key)}")
        if openai_key:
            print(f"ğŸ”¥ [DEBUG] OPENAI_API_KEY ì• 8ê¸€ì: {openai_key[:8]}...")
        if not openai_key:
            print("ğŸ”¥ [DEBUG] API í‚¤ ì—†ìŒ - 500 ì—ëŸ¬ ë°˜í™˜")
            print("[ê²½ê³ ] OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500
        
        cmd_args = [
            sys.executable, 'build_faiss_and_query.py',
            '--demo_query', query,
            '--llm_filter',
            '--save_web',
            '--openai_key', openai_key,
            '--top_k', '20'  # ì ì ˆí•œ í›„ë³´êµ° ìˆ˜, LLMì´ í•„í„°ë§í•¨
        ]
        
        print(f"ğŸ”¥ [DEBUG] subprocess ì‹¤í–‰: {' '.join(cmd_args[:6])}...")
        
        # í™˜ê²½ë³€ìˆ˜ì— UTF-8 ì„¤ì • ì¶”ê°€
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['PYTHONUTF8'] = '1'  # Python 3.7+ UTF-8 ëª¨ë“œ
        
        try:
            # í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: Popenìœ¼ë¡œ í”„ë¡œì„¸ìŠ¤ ì¶”ì í•˜ë˜ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            process = subprocess.Popen(
                cmd_args, 
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=os.getcwd(),
                env=env,
                encoding='utf-8',  # ëª…ì‹œì  ì¸ì½”ë”© ì„¤ì •
                errors='ignore'    # ì¸ì½”ë”© ì—ëŸ¬ ë¬´ì‹œ
            )
            
            # í”„ë¡œì„¸ìŠ¤ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì—¬ ì¶”ì 
            global active_processes
            active_processes.append(process)
            
            # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ í¬í•¨)
            try:
                stdout, stderr = process.communicate(timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
            except subprocess.TimeoutExpired:
                print(f"ğŸ”¥ [DEBUG] subprocess íƒ€ì„ì•„ì›ƒ - ê°•ì œ ì¢…ë£Œ")
                process.kill()
                stdout, stderr = process.communicate()
                return jsonify({'error': 'ê²€ìƒ‰ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'}), 500
            
            # ì™„ë£Œëœ í”„ë¡œì„¸ìŠ¤ëŠ” ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±°
            if process in active_processes:
                active_processes.remove(process)
                
            print(f"ğŸ”¥ [DEBUG] subprocess ì¢…ë£Œ ì½”ë“œ: {process.returncode}")
            if stderr:
                print(f"ğŸ”¥ [DEBUG] subprocess stderr: {stderr[:200]}...")
            if stdout:
                print(f"ğŸ”¥ [DEBUG] subprocess stdout: {stdout[:200]}...")
            
            if process.returncode != 0:
                print(f"ğŸ”¥ [DEBUG] subprocess ì‹¤íŒ¨ - 500 ì—ëŸ¬ ë°˜í™˜")
                print(f"[ì˜¤ë¥˜] ê²€ìƒ‰ ì‹¤íŒ¨: {stderr}")
                return jsonify({'error': 'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500
                
        except subprocess.TimeoutExpired:
            print(f"ğŸ”¥ [DEBUG] subprocess íƒ€ì„ì•„ì›ƒ (5ë¶„ ì´ˆê³¼)")
            return jsonify({'error': 'ê²€ìƒ‰ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'}), 500
        except Exception as e:
            print(f"ğŸ”¥ [DEBUG] subprocess ì‹¤í–‰ ì¤‘ ì˜ˆì™¸: {e}")
            return jsonify({'error': f'ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}'}), 500
        
        # ê²°ê³¼ ë¡œë“œ
        web_results_path = Path('web_results.json')
        if not web_results_path.exists():
            return jsonify({'error': 'ê²€ìƒ‰ ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500
        
        with open(web_results_path, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # LLM ë¶„ì„ ê²°ê³¼ í™•ì¸ì„ ìœ„í•œ ë””ë²„ê·¸ ì¶œë ¥
        movies = results.get('movies', [])
        llm_count = 0
        for movie in movies:
            if movie and isinstance(movie, dict):
                title = movie.get('title')
                llm_analysis = movie.get('llm_analysis')
                if llm_analysis and isinstance(llm_analysis, dict):
                    llm_reason = llm_analysis.get('reason', '')
                    if title and llm_reason:
                        llm_count += 1
                        print(f"[ë””ë²„ê·¸] LLM ë¶„ì„ ì™„ë£Œ: {title}")
        
        print(f"[ì„±ê³µ] {len(results['movies'])}ê°œ ì˜í™” ê²€ìƒ‰ ì™„ë£Œ, {llm_count}ê°œ LLM ë¶„ì„ ì™„ë£Œ")
        return jsonify(results)
        
    except Exception as e:
        print(f"[ì˜ˆì™¸] ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/stream-search', methods=['GET'])
def stream_search():
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ê²€ìƒ‰ - LLM ë¶„ì„ ì™„ë£Œë˜ëŠ” ëŒ€ë¡œ ê²°ê³¼ ì „ì†¡"""
    # request contextê°€ í™œì„±í™”ëœ ìƒíƒœì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    query = request.args.get('query', '').strip()
    
    def generate_stream():
        try:
            if not query:
                yield f"data: {json.dumps({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})}\n\n"
                return
            
            # ì´ˆê¸° ìƒíƒœ ì „ì†¡
            yield f"data: {json.dumps({'status': 'searching', 'message': f'ê²€ìƒ‰ ì¤‘: {query}'})}\n\n"
            
            # subprocess ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼í•˜ì§€ë§Œ ì‹¤ì‹œê°„ ì²˜ë¦¬)
            openai_key = os.getenv('OPENAI_API_KEY')
            if not openai_key:
                yield f"data: {json.dumps({'error': 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'})}\n\n"
                return
            
            cmd_args = [
                sys.executable, 'build_faiss_and_query.py',
                '--demo_query', query,
                '--llm_filter',
                '--save_web',
                '--openai_key', openai_key,
                '--top_k', '20'
            ]
            
            # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            env = os.environ.copy()
            env['PYTHONIOENCODING'] = 'utf-8'
            env['PYTHONUTF8'] = '1'
            
            # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
            process = subprocess.Popen(
                cmd_args, 
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=os.getcwd(),
                env=env,
                encoding='utf-8',
                errors='ignore'
            )
            
            global active_processes
            active_processes.append(process)
            
            # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
            try:
                stdout, stderr = process.communicate(timeout=300)
                
                if process in active_processes:
                    active_processes.remove(process)
                
                if process.returncode == 0:
                    # ì™„ë£Œ í›„ ê²°ê³¼ íŒŒì¼ ì½ê¸°
                    web_results_path = Path('web_results.json')
                    if web_results_path.exists():
                        with open(web_results_path, 'r', encoding='utf-8') as f:
                            results = json.load(f)
                        
                        # ê° ì˜í™”ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì „ì†¡ (ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼)
                        movies = results.get('movies', [])
                        for i, movie in enumerate(movies):
                            yield f"data: {json.dumps({'type': 'movie', 'data': movie, 'index': i, 'total': len(movies)})}\n\n"
                            time.sleep(0.1)  # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ë¥¼ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°
                        
                        yield f"data: {json.dumps({'status': 'completed', 'message': 'ê²€ìƒ‰ ì™„ë£Œ', 'total_results': len(movies)})}\n\n"
                    else:
                        yield f"data: {json.dumps({'error': 'ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})}\n\n"
                else:
                    yield f"data: {json.dumps({'error': 'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'})}\n\n"
                    
            except subprocess.TimeoutExpired:
                process.kill()
                stdout, stderr = process.communicate()
                yield f"data: {json.dumps({'error': 'ê²€ìƒ‰ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.'})}\n\n"
                
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return Response(generate_stream(), mimetype='text/event-stream')

@app.route('/streaming-search', methods=['POST'])
def streaming_search():
    """ì‹¤ì‹œê°„ LLM ë¶„ì„ ìŠ¤íŠ¸ë¦¬ë° - ë¶„ì„ ì™„ë£Œëœ ì˜í™”ë¥¼ í•˜ë‚˜ì”© ì „ì†¡"""
    try:
        print("ğŸ¬ [ìŠ¤íŠ¸ë¦¬ë°] ì‹¤ì‹œê°„ LLM ë¶„ì„ ì‹œì‘!")
        data = request.get_json()
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400
        
        # OpenAI API í‚¤ í™•ì¸
        openai_key = os.getenv('OPENAI_API_KEY')
        if not openai_key:
            return jsonify({'error': 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500

        def generate_streaming_results():
            global global_sentence_model  # â­ ì „ì—­ ë³€ìˆ˜ ì„ ì–¸ ì¶”ê°€
            try:
                # 1. FAISS ê²€ìƒ‰ (ë¹ ë¥¸ í›„ë³´ ì„ ë³„)
                yield f"data: {json.dumps({'status': 'searching', 'message': 'FAISS ê²€ìƒ‰ ì¤‘...'})}\n\n"
                
                # ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (ì´ë¯¸ ì‚¬ì „ ë¡œë”©ë¨)
                if global_sentence_model is None:
                    yield f"data: {json.dumps({'status': 'loading', 'message': 'ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...'})}\n\n"
                    from sentence_transformers import SentenceTransformer
                    import torch
                    device = 'cuda' if torch.cuda.is_available() else 'cpu'
                    global_sentence_model = SentenceTransformer(
                        'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                        device=device
                    )

                model = global_sentence_model
                
                # ì„ë² ë”© ìƒì„± ë° ê²€ìƒ‰
                import torch
                with torch.inference_mode():
                    q = model.encode([query], convert_to_numpy=True, normalize_embeddings=False).astype('float32')
                q = ensure_unit_norm(q)
                
                # FAISS ê²€ìƒ‰
                top_k = 20
                top_k_search = top_k * 2  # ì—¬ìœ  ìˆê²Œ ê²€ìƒ‰
                sims, ids = query_index(global_index, q, top_k=top_k_search)
                
                # ì˜í™”ë³„ ì§‘ê³„
                final_sims, final_ids, final_metas = aggregate_by_movie(sims, ids, global_metadata, top_k=top_k)
                
                yield f"data: {json.dumps({'status': 'llm_start', 'message': f'LLM ë¶„ì„ ì‹œì‘ ({len(final_metas)}ê°œ ì˜í™”)', 'total_movies': len(final_metas)})}\n\n"
                
                # 2. ğŸŒŸ ì‹¤ì‹œê°„ LLM ë¶„ì„ ë° ìŠ¤íŠ¸ë¦¬ë°
                llm_filter = LLMMovieFilter(openai_key)
                approved_count = 0
                
                for i, meta in enumerate(final_metas):
                    try:
                        movie_data = {
                            **meta,
                            'score': float(final_sims[0][i])
                        }
                        
                        # ë¶„ì„ ì§„í–‰ ìƒí™© ì „ì†¡
                        title = movie_data.get('title', 'Unknown')
                        message = f'[{i+1}/{len(final_metas)}] {title} ë¶„ì„ ì¤‘...'
                        yield f"data: {json.dumps({'status': 'analyzing', 'message': message, 'current': i+1, 'total': len(final_metas)})}\n\n"
                        
                        # LLM ë¶„ì„
                        judgment = llm_filter._analyze_movie_relevance(query, movie_data)
                        
                        if judgment['pass'] and judgment['score'] >= 7:  # í†µê³¼í•œ ì˜í™”ë§Œ
                            approved_count += 1
                            
                            # í¬ë§·íŒ…
                            formatted_movie = {
                                "title": movie_data.get('title', ''),
                                "year": movie_data.get('year', ''),
                                "director": movie_data.get('director', ''),
                                "score": movie_data.get('score', 0),
                                "poster_url": f"/static/posters/{movie_data.get('title', '').replace(':', '').replace('/', '_')}.jpg",
                                "llm_analysis": {
                                    "score": judgment['score'],
                                    "reason": judgment['reason']
                                }
                            }
                            
                            # âœ¨ í†µê³¼í•œ ì˜í™”ë¥¼ ì¦‰ì‹œ ì „ì†¡!
                            yield f"data: {json.dumps({'type': 'approved_movie', 'data': formatted_movie, 'approved_count': approved_count, 'progress': i+1, 'total': len(final_metas)})}\n\n"
                            print(f"    âœ… [PASS] {movie_data.get('title')} (ì ìˆ˜: {judgment['score']}/10) - ì¦‰ì‹œ ì „ì†¡ë¨")
                        else:
                            print(f"    âŒ [FAIL] {movie_data.get('title')} (ì ìˆ˜: {judgment['score']}/10)")
                        
                        # API ì œí•œ ê³ ë ¤
                        time.sleep(0.4)
                        
                    except Exception as e:
                        yield f"data: {json.dumps({'status': 'error', 'message': f'ì˜í™” {i+1} ë¶„ì„ ì˜¤ë¥˜: {str(e)}'})}\n\n"
                
                # ì™„ë£Œ ë©”ì‹œì§€
                yield f"data: {json.dumps({'status': 'completed', 'message': f'ê²€ìƒ‰ ì™„ë£Œ: {approved_count}ê°œ ì˜í™” ì¶”ì²œ', 'approved_count': approved_count})}\n\n"
                print(f"ğŸ‰ [ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ] ì´ {approved_count}ê°œ ì˜í™” ìŠ¹ì¸ë¨")
                
            except Exception as e:
                yield f"data: {json.dumps({'error': f'ìŠ¤íŠ¸ë¦¬ë° ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}'})}\n\n"
        
        return Response(stream_with_context(generate_streaming_results()), 
                       mimetype='text/event-stream',
                       headers={
                           'Cache-Control': 'no-cache',
                           'Connection': 'keep-alive',
                           'Access-Control-Allow-Origin': '*'
                       })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/fast-search', methods=['POST'])
def fast_search():
    """ì‚¬ì „ ë¡œë”©ëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¹ ë¥¸ ê²€ìƒ‰"""
    try:
        print("\n" + "="*50)
        print("ğŸ”¥ [DEBUG] /fast-search ì—”ë“œí¬ì¸íŠ¸ ì§„ì…!")
        print("ğŸ”¥ [DEBUG] ìš”ì²­ ë©”ì„œë“œ:", request.method)
        print("ğŸ”¥ [DEBUG] ìš”ì²­ í—¤ë”:", dict(request.headers))
        
        data = request.get_json()
        print("ğŸ”¥ [DEBUG] ë°›ì€ JSON ë°ì´í„°:", data)
        
        query = data.get('query', '').strip() if data else ''
        print(f"ğŸ”¥ [DEBUG] ì¶”ì¶œëœ ê²€ìƒ‰ì–´: '{query}'")
        
        if not query:
            print("ğŸ”¥ [DEBUG] ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ìˆìŒ")
            return jsonify({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400
        
        # ëª¨ë¸ ë¡œë”© í™•ì¸
        print(f"ğŸ”¥ [DEBUG] global_models_loaded: {global_models_loaded}")
        print(f"ğŸ”¥ [DEBUG] global_index is None: {global_index is None}")
        print(f"ğŸ”¥ [DEBUG] global_metadata is None: {global_metadata is None}")
        
        if not global_models_loaded or global_index is None or global_metadata is None:
            print("ğŸ”¥ [DEBUG] ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•ŠìŒ - í´ë°± ê²€ìƒ‰")
            return handle_regular_search_fallback(query)
        
        print(f"ğŸ”¥ [DEBUG] ì‚¬ì „ ë¡œë”©ëœ ëª¨ë¸ ì‚¬ìš© - ë¹ ë¥¸ ê²€ìƒ‰ ì‹œì‘")
        print("="*50 + "\n")
        
        # ì§ì ‘ ê²€ìƒ‰ ì‹¤í–‰ (subprocess ì—†ì´)
        return perform_direct_search(query)
        
    except Exception as e:
        print(f"[ì˜ˆì™¸] ë¹ ë¥¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

def perform_direct_search(query):
    """build_faiss_and_query.pyì˜ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•œ ì§ì ‘ ê²€ìƒ‰"""
    global global_sentence_model  # â­ ì „ì—­ ë³€ìˆ˜ ì„ ì–¸ ì¶”ê°€
    
    try:
        start_time = time.time()
        print(f"ğŸš€ [ì§ì ‘ ê²€ìƒ‰] '{query}' ê²€ìƒ‰ ì‹œì‘...")
        
        # OpenAI API í‚¤ í™•ì¸
        openai_key = os.getenv('OPENAI_API_KEY')
        if not openai_key:
            return jsonify({'error': 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500
        
        # 1. ì„ë² ë”© ìƒì„± (ì‚¬ì „ ë¡œë”©ëœ ëª¨ë¸ ì‚¬ìš©)
        embed_start = time.time()
        
        if global_sentence_model is None:
            from sentence_transformers import SentenceTransformer
            import torch
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            print(f"ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... (device: {device})")
            global_sentence_model = SentenceTransformer(
                'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                device=device
            )
            print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        model = global_sentence_model
        
        # ì„ë² ë”© ìƒì„± ë° ì •ê·œí™” (build_faiss_and_query.pyì™€ ë™ì¼í•œ ë°©ì‹)
        import torch
        with torch.inference_mode():
            q = model.encode([query], convert_to_numpy=True, normalize_embeddings=False).astype('float32')
        q = ensure_unit_norm(q)  # build_faiss_and_query.pyì˜ ì •ê·œí™” í•¨ìˆ˜ ì‚¬ìš©
        
        embed_time = time.time() - embed_start
        print(f"âš¡ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {embed_time:.2f}ì´ˆ")
        
        # 2. FAISS ê²€ìƒ‰ (build_faiss_and_query.pyì™€ ë™ì¼í•œ ë°©ì‹)
        search_start = time.time()
        top_k = 20  # ìµœì¢… ê²°ê³¼ ê°œìˆ˜
        top_k_search = top_k * 3  # build_faiss_and_query.pyì™€ ë™ì¼: ë” ë§ì´ ê²€ìƒ‰í•´ì„œ ì§‘ê³„
        
        sims, ids = query_index(global_index, q, top_k=top_k_search)  # build_faiss_and_query.py í•¨ìˆ˜ ì‚¬ìš©
        search_time = time.time() - search_start
        print(f"âš¡ FAISS ê²€ìƒ‰ ì™„ë£Œ: {search_time:.2f}ì´ˆ (ì´ˆê¸° {top_k_search}ê°œ)")
        
        # 3. ì˜í™”ë³„ ì§‘ê³„ (build_faiss_and_query.pyì˜ ì •í™•í•œ í•¨ìˆ˜ ì‚¬ìš©)
        aggregate_start = time.time()
        final_sims, final_ids, final_metas = aggregate_by_movie(sims, ids, global_metadata, top_k=top_k)
        aggregate_time = time.time() - aggregate_start
        print(f"âš¡ ì˜í™”ë³„ ì§‘ê³„ ì™„ë£Œ: {aggregate_time:.2f}ì´ˆ (ìµœì¢… {len(final_metas)}ê°œ)")
        
        # 4. LLM í•„í„°ë§ (build_faiss_and_query.pyì™€ ë™ì¼í•œ ë°©ì‹)
        llm_start = time.time()
        print(f"ğŸ¤– LLM í•„í„°ë§ ì‹œì‘... ({len(final_metas)}ê°œ ì˜í™”)")
        
        # ë©”íƒ€ë°ì´í„°ë¥¼ LLM í•„í„°ë§ìš© í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        movies_for_filtering = []
        for i, meta in enumerate(final_metas):
            movies_for_filtering.append({
                **meta,
                'score': float(final_sims[0][i])
            })
        
        # LLM í•„í„°ë§ ì‹¤í–‰ (build_faiss_and_query.py í•¨ìˆ˜ ì‚¬ìš©)
        llm_filter = LLMMovieFilter(openai_key)
        filtered_movies = llm_filter.filter_search_results(
            query=query,
            movies=movies_for_filtering,
            threshold=7
        )
        
        llm_time = time.time() - llm_start
        print(f"âš¡ LLM í•„í„°ë§ ì™„ë£Œ: {llm_time:.2f}ì´ˆ ({len(final_metas)} â†’ {len(filtered_movies)}ê°œ)")
        
        # 5. ì›¹ ê²°ê³¼ í¬ë§·íŒ… (build_faiss_and_query.py í•¨ìˆ˜ ì‚¬ìš©)
        format_start = time.time()
        web_results = format_results_for_web(
            movies=filtered_movies,
            query=query,
            llm_filtered=True
        )
        format_time = time.time() - format_start
        print(f"âš¡ ê²°ê³¼ í¬ë§·íŒ… ì™„ë£Œ: {format_time:.2f}ì´ˆ")
        
        # ì´ ì‹œê°„ ì¶œë ¥
        total_time = time.time() - start_time
        print(f"ğŸ‰ [ì§ì ‘ ê²€ìƒ‰ ì™„ë£Œ] ì´ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   - ì„ë² ë”©: {embed_time:.2f}ì´ˆ")
        print(f"   - FAISS ê²€ìƒ‰: {search_time:.2f}ì´ˆ") 
        print(f"   - ì˜í™” ì§‘ê³„: {aggregate_time:.2f}ì´ˆ")
        print(f"   - LLM í•„í„°ë§: {llm_time:.2f}ì´ˆ")
        print(f"   - ê²°ê³¼ í¬ë§·íŒ…: {format_time:.2f}ì´ˆ")
        
        return web_results
        
    except Exception as e:
        print(f"âŒ [ì˜¤ë¥˜] ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {'error': str(e)}

def handle_regular_search_fallback(query):
    """ê¸°ì¡´ ê²€ìƒ‰ ë¡œì§ (í´ë°±ìš©)"""
    try:
        openai_key = os.getenv('OPENAI_API_KEY')
        if not openai_key:
            return jsonify({'error': 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500
        
        cmd_args = [
            sys.executable, 'build_faiss_and_query.py',
            '--demo_query', query,
            '--llm_filter',
            '--save_web',
            '--openai_key', openai_key,
            '--top_k', '20'
        ]
        
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['PYTHONUTF8'] = '1'
        
        result = subprocess.run(
            cmd_args, 
            capture_output=True,
            text=True,
            cwd=os.getcwd(),
            env=env,
            timeout=300,
            encoding='utf-8',
            errors='ignore'
        )
            
        if result.returncode != 0:
            return jsonify({'error': 'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500
        
        # ê²°ê³¼ ë¡œë“œ
        web_results_path = Path('web_results.json')
        if not web_results_path.exists():
            return jsonify({'error': 'ê²€ìƒ‰ ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500
        
        with open(web_results_path, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        return jsonify(results)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500
def explain_movie(movie_title):
    """ì˜í™” ì¶”ì²œ ì´ìœ  ì„¤ëª… (ì œëª© ê¸°ë°˜) - JSON íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°"""
    try:
        # web_results.jsonì—ì„œ ì˜í™” ì„¤ëª… ì½ê¸°
        web_results_path = Path('web_results.json')
        if not web_results_path.exists():
            return jsonify({'error': 'ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 404
            
        with open(web_results_path, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # URL ë””ì½”ë”©
        movie_title = movie_title.strip()
        
        print(f"[ë””ë²„ê·¸] ìš”ì²­ëœ ì˜í™”: '{movie_title}'")
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•´ë‹¹ ì œëª©ì˜ ì˜í™” ì°¾ê¸°
        movies = results.get('movies', [])
        for movie in movies:
            if movie and isinstance(movie, dict):
                title = movie.get('title', '')
                if title == movie_title:
                    llm_analysis = movie.get('llm_analysis')
                    if llm_analysis and isinstance(llm_analysis, dict):
                        explanation = llm_analysis.get('reason', '')
                        if explanation:
                            return jsonify({
                                'title': title,
                                'explanation': explanation
                            })
        
        # ì°¾ì§€ ëª»í•œ ê²½ìš°
        return jsonify({'error': f'"{movie_title}" ì˜í™”ì˜ ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
    except Exception as e:
        print(f"[ì˜ˆì™¸] ì„¤ëª… ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/movie/<int:movie_rank>')
def movie_detail(movie_rank):
    """ì˜í™” ìƒì„¸ ì •ë³´ í˜ì´ì§€"""
    try:
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì˜í™” ì •ë³´ ë¡œë“œ
        web_results_path = Path('web_results.json')
        if not web_results_path.exists():
            return render_template('error.html', message='ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        
        with open(web_results_path, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        movies = results.get('movies', [])
        if movie_rank < 1 or movie_rank > len(movies):
            return render_template('error.html', message='ìœ íš¨í•˜ì§€ ì•Šì€ ì˜í™”ì…ë‹ˆë‹¤.')
        
        movie = movies[movie_rank - 1]
        return render_template('movie_detail.html', movie=movie, query=results.get('query'))
        
    except Exception as e:
        print(f"[ì˜ˆì™¸] ì˜í™” ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return render_template('error.html', message='ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')

@app.route('/explanation/<movie_title>')
def get_explanation_by_title(movie_title):
    """ì˜í™” ì œëª©ìœ¼ë¡œ ì¶”ì²œ ì´ìœ  ì¡°íšŒ - JSON íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°"""
    return explain_movie(movie_title)  # ìœ„ì˜ í•¨ìˆ˜ë¥¼ ì¬ì‚¬ìš©

@app.route('/explanations')
def get_all_explanations():
    """ëª¨ë“  ì˜í™” ì„¤ëª… ë°ì´í„° ì¡°íšŒ - JSON íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°"""
    try:
        web_results_path = Path('web_results.json')
        if not web_results_path.exists():
            return jsonify({'explanations': []})
            
        with open(web_results_path, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        explanations = []
        movies = results.get('movies', [])
        for movie in movies:
            if movie and isinstance(movie, dict):
                title = movie.get('title', '')
                llm_analysis = movie.get('llm_analysis')
                if llm_analysis and isinstance(llm_analysis, dict):
                    explanation = llm_analysis.get('reason', '')
                    if title and explanation:
                        explanations.append([title, explanation])
        
        return jsonify({
            'explanations': explanations,
            'count': len(explanations)
        })
    except Exception as e:
        print(f"[ì˜ˆì™¸] ì „ì²´ ì„¤ëª… ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

# ì •ì  íŒŒì¼ ì œê³µì„ ìœ„í•œ ë¼ìš°íŠ¸
@app.route('/static/posters/<filename>')
def serve_poster(filename):
    """í¬ìŠ¤í„° ì´ë¯¸ì§€ ì œê³µ (ê¸°ë³¸ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´)"""
    # ì‹¤ì œ í¬ìŠ¤í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
    return app.send_static_file(f'images/default_poster.jpg')

if __name__ == '__main__':
    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('templates', exist_ok=True)
    os.makedirs('static/css', exist_ok=True)
    os.makedirs('static/js', exist_ok=True)
    os.makedirs('static/images', exist_ok=True)
    
    print("ğŸ¬ ì˜í™” ì¶”ì²œ ì›¹ ì„œë²„ ì‹œì‘")
    print("ğŸ“ http://localhost:5000 ì—ì„œ ì ‘ì†í•˜ì„¸ìš”")
    print("âš ï¸  ì„œë²„ ì¢…ë£Œ ì‹œ Ctrl+Cë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”")
    
    # ğŸš€ ëª¨ë¸ ì‚¬ì „ ë¡œë”©ì€ ì²« ìš”ì²­ì—ì„œ ì‹¤í–‰
    # with app.app_context():
    #     load_models_on_startup()
    
    try:
        # í”„ë¡œì„¸ìŠ¤ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ use_reloader=False ì„¤ì •
        # debug=TrueëŠ” ìœ ì§€í•˜ë˜ auto-reload ê¸°ëŠ¥ ë¹„í™œì„±í™”
        app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=False, threaded=True)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì„œë²„ ì¢…ë£Œ ì¤‘...")
        # ê°•ì œ ì¢…ë£Œë¡œ í™•ì‹¤í•˜ê²Œ ì •ë¦¬
        os._exit(0)